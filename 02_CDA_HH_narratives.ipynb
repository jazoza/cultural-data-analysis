{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jazoza/cultural-data-analysis/blob/main/02_CDA_HH_narratives.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cultural Data Analysis\n",
        "\n",
        "Introduction to working with datasets"
      ],
      "metadata": {
        "id": "7CC34uuNzNxY"
      },
      "id": "7CC34uuNzNxY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76a4e150-cc6f-4878-a32b-e78a1d6426ae",
      "metadata": {
        "id": "76a4e150-cc6f-4878-a32b-e78a1d6426ae"
      },
      "outputs": [],
      "source": [
        "# import necessary libraries\n",
        "import os, re, csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from collections import Counter\n",
        "from itertools import islice\n",
        "from nltk.corpus import stopwords\n",
        "import spacy\n",
        "import string\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7010dda9-acc5-4d90-b175-90012564d13c",
      "metadata": {
        "id": "7010dda9-acc5-4d90-b175-90012564d13c"
      },
      "source": [
        "## Loading the dataset: heritage homes webistes\n",
        "\n",
        "The dataset is stored in a shared google drive:\n",
        "https://drive.google.com/drive/folders/11Shm0edDOiWrOe56fzJQRZi-v_BPSW8E?usp=drive_link\n",
        "\n",
        "Add it to your drive.\n",
        "\n",
        "To access it, load your gdrive in 'Files' (see left pane of the notebook in google colab) and navigate to the shared folder. You may need to click on 'refresh' to make it appear on the list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d42429d3-63fe-4b79-b341-160057e5dcbc",
      "metadata": {
        "id": "d42429d3-63fe-4b79-b341-160057e5dcbc"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Country code: change here between 'NL' and 'UK'\n",
        "cc = 'UK'"
      ],
      "metadata": {
        "id": "QYiHwjcORrPC"
      },
      "id": "QYiHwjcORrPC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gdrive_path = '/content/gdrive/MyDrive/CDA/'"
      ],
      "metadata": {
        "id": "bbjhZ8nKZtZC"
      },
      "id": "bbjhZ8nKZtZC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# open the data for one country (cc)\n",
        "raw_data_file = gdrive_path+cc+'_dataset_website-content-crawler.json'"
      ],
      "metadata": {
        "id": "yCPPY_4I2pIZ"
      },
      "id": "yCPPY_4I2pIZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8697b51f-50a5-4091-9cc1-0aed1308b27d",
      "metadata": {
        "id": "8697b51f-50a5-4091-9cc1-0aed1308b27d"
      },
      "outputs": [],
      "source": [
        "# Import json data\n",
        "df=pd.read_json(raw_data_file)\n",
        "\n",
        "# Print the DataFrame\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check if there are further datasets to add per country\n",
        "\n",
        "!ls \"$gdrive_path\" | grep 'UK'"
      ],
      "metadata": {
        "id": "uffqK0WpzBmi"
      },
      "id": "uffqK0WpzBmi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_missing1 = pd.read_json(gdrive_path+'/UK_EH_dataset_website-content-crawler_2025-03-26_09-11-52-434.json')\n",
        "df_missing2 = pd.read_json(gdrive_path+'/UK_NH_dataset_website-content-crawler_2025-03-26_16-28-44-248.json')\n",
        "df_missing3 = pd.read_json(gdrive_path+'/UK_PC_dataset_website-content-crawler_2025-03-11_12-28-08-810.json')\n",
        "result = pd.concat([df, df_missing1, df_missing2, df_missing3])\n",
        "df = result\n",
        "df.head()"
      ],
      "metadata": {
        "id": "awG55UfmzkCr"
      },
      "id": "awG55UfmzkCr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a4128d6-4115-47a6-9e78-5a517bded844",
      "metadata": {
        "id": "6a4128d6-4115-47a6-9e78-5a517bded844"
      },
      "outputs": [],
      "source": [
        "# select only two columns for analysis: url and text\n",
        "df=df[['url','text']]\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Join all pages from a domain to an entry in the analysis. To do this, add a new column which will contain only the main domain name."
      ],
      "metadata": {
        "id": "Rr6hiPQ-4z5O"
      },
      "id": "Rr6hiPQ-4z5O"
    },
    {
      "cell_type": "code",
      "source": [
        "# function to extract the main domain from the url in the dataset\n",
        "def extract_main_domain(url):\n",
        "    if not isinstance(str(url), str):\n",
        "        print('NOT VALID',url)\n",
        "        return None\n",
        "    match = re.findall('(?:\\w+\\.)*\\w+\\.\\w*', str(url)) #'www\\.?([^/]+)'\n",
        "    return match[0].lstrip('www.') if match else None"
      ],
      "metadata": {
        "id": "_Px9Aoim4-pq"
      },
      "id": "_Px9Aoim4-pq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47db9deb-8836-47fb-9f74-28a023bcb5d7",
      "metadata": {
        "id": "47db9deb-8836-47fb-9f74-28a023bcb5d7"
      },
      "outputs": [],
      "source": [
        "# Load the list of domains from a csv file:\n",
        "cc_column = cc+' domains'\n",
        "#print(cc_column)\n",
        "\n",
        "urls = pd.read_csv(gdrive_path+'url_lists/'+cc+'_urls.csv')[cc_column].values.tolist()\n",
        "\n",
        "# Extract main domains from nl_urls\n",
        "domains = {extract_main_domain(url) for url in urls if extract_main_domain(url) is not None}\n",
        "\n",
        "# Check if main domains in list_of_links match any domain in nl_domains\n",
        "matching_links = [link for link in df.url if extract_main_domain(link) in domains]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a2e8c0b-4c0e-4445-a5bb-2f1695ad353e",
      "metadata": {
        "id": "2a2e8c0b-4c0e-4445-a5bb-2f1695ad353e"
      },
      "outputs": [],
      "source": [
        "# this cell can be skipped, it is only for verification\n",
        "\n",
        "# check how many lines in the dataframe have a matching link to the list of urls\n",
        "print(len(matching_links))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc9d2331-fe01-4e94-b984-00ac834a771c",
      "metadata": {
        "id": "cc9d2331-fe01-4e94-b984-00ac834a771c"
      },
      "outputs": [],
      "source": [
        "# Add a new column 'domain' and fill it by applying the extract_main_domain function to the 'url' column\n",
        "df['domain'] = df['url'].apply(extract_main_domain)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A. Scrape webpages: screenshots\n",
        "\n",
        "Automatically make screenshots of all urls, and save them to your local drive for later analysis.\n",
        "\n",
        "Code to do this is available elsewhere.\n",
        "\n",
        "Analyze: https://medium.com/@sehjadkhoja0/title-exploring-and-analyzing-image-data-with-python-79a7f72f4d2b"
      ],
      "metadata": {
        "id": "y87AvOKE5UKj"
      },
      "id": "y87AvOKE5UKj"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5734e29"
      },
      "source": [
        "# Install Playwright library\n",
        "!pip install playwright\n",
        "# Install Playwright's browser binaries (Chromium, Firefox, WebKit)\n",
        "!playwright install\n",
        "!playwright install-deps"
      ],
      "id": "d5734e29",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from playwright.async_api import async_playwright\n",
        "\n",
        "# Define the output directory\n",
        "output_dir = '/content/sample_data/'"
      ],
      "metadata": {
        "id": "dxXd7a1AQ9NU"
      },
      "id": "dxXd7a1AQ9NU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5382d1f"
      },
      "source": [
        "async def take_screenshots():\n",
        "    async with async_playwright() as p:\n",
        "        # Use Chromium as the browser\n",
        "        browser = await p.chromium.launch(headless=True)\n",
        "        page = await browser.new_page()\n",
        "\n",
        "        for i, url in enumerate(urls):\n",
        "            try:\n",
        "                print(f\"Navigating to: {url}\")\n",
        "                await page.goto(url, wait_until='networkidle') # wait for network to be idle\n",
        "\n",
        "                # Sanitize the URL to create a valid filename\n",
        "                filename = f\"screenshot_{i}_{url.replace('https://', '').replace('http://', '').replace('/', '_').replace('.', '_')}.png\"\n",
        "                filepath = os.path.join(output_dir, filename)\n",
        "\n",
        "                # Take full-page screenshot\n",
        "                await page.screenshot(path=filepath, full_page=True)\n",
        "                print(f\"Screenshot saved: {filepath}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error taking screenshot for {url}: {e}\")\n",
        "        await browser.close()\n",
        "        print(\"Screenshot process completed.\")\n",
        "\n",
        "# Run the async function\n",
        "await take_screenshots()"
      ],
      "id": "e5382d1f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OPTIONAL\n",
        "# compress all image files and download the 'sample_data_screenshots' zip file to your local folder for later\n",
        "# you have to save it manually by navigating to the 'folder' icon (left pane) and selecting the 3 vertical dots next to sample_data_screenshots.zip\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import glob\n",
        "\n",
        "# Define the output directory and zip filename\n",
        "zip_filename = 'sample_data_screenshots.zip'\n",
        "\n",
        "# Create a new zip file and add only .png files\n",
        "with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
        "    # Find all .png files recursively starting from output_dir\n",
        "    png_files = glob.glob(os.path.join(output_dir, '**', '*.png'), recursive=True)\n",
        "    for file_path in png_files:\n",
        "        # Ensure the path inside the zip is relative to the output_dir\n",
        "        arcname = os.path.relpath(file_path, output_dir)\n",
        "        zipf.write(file_path, arcname=arcname)\n"
      ],
      "metadata": {
        "id": "LgrGtwiahqAI"
      },
      "id": "LgrGtwiahqAI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A.1 Visualize image properties\n",
        "\n",
        "Calculate and visualize the size (MB) and resolution (width, height in pixels) for all images"
      ],
      "metadata": {
        "id": "6aSGrJEWhfxz"
      },
      "id": "6aSGrJEWhfxz"
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the size (MB)\n",
        "\n",
        "import cv2\n",
        "import plotly.express as px\n",
        "\n",
        "# Root directory path\n",
        "root_path = \"sample_data/\"\n",
        "\n",
        "# List to store file sizes\n",
        "sizes = []\n",
        "\n",
        "# Iterate over each image file in each subdirectory\n",
        "for dirpath, dirnames, filenames in os.walk(root_path):\n",
        "    for filename in filenames:\n",
        "        if filename.lower().endswith(('.png')):\n",
        "            # Load the image file using OpenCV\n",
        "            img_path = os.path.join(dirpath, filename)\n",
        "            img = cv2.imread(img_path)\n",
        "\n",
        "            # Extract the size of the image\n",
        "            size = os.path.getsize(img_path)\n",
        "            sizes.append(size)\n",
        "\n",
        "# Convert the lists to numpy arrays for easier manipulation\n",
        "sizes = np.array(sizes)\n",
        "\n",
        "# Create a histogram figure with plotly\n",
        "fig = px.histogram(x=sizes, nbins=50, title=\"Distribution of Image Sizes\")\n",
        "\n",
        "# Customize the plot\n",
        "fig.update_layout(\n",
        "    xaxis_title=\"File Size (MB)\",\n",
        "    yaxis_title=\"Number of Images\",\n",
        "    showlegend=False,\n",
        "    bargap=0.1,\n",
        "    bargroupgap=0.1\n",
        ")\n",
        "\n",
        "# Show the plot\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "DAlIhV8bU8B_"
      },
      "id": "DAlIhV8bU8B_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate resolution\n",
        "\n",
        "resolutions = [] # this will tell us how 'long' the pages are, given that they all have the same width in the browser screenshot\n",
        "\n",
        "# Iterate over each image file in each subdirectory\n",
        "for dirpath, dirnames, filenames in os.walk(root_path):\n",
        "    for filename in filenames:\n",
        "        if filename.lower().endswith(('.png')):\n",
        "            # Load the image file using OpenCV\n",
        "            img_path = os.path.join(dirpath, filename)\n",
        "            img = cv2.imread(img_path)\n",
        "\n",
        "            # Extract the resolution of the image\n",
        "            resolution = img.shape[:2]\n",
        "            resolutions.append(resolution)\n",
        "\n",
        "# Convert the lists to numpy arrays for easier manipulation\n",
        "resolutions = np.array(resolutions)"
      ],
      "metadata": {
        "id": "mInfSh2tVbuH"
      },
      "id": "mInfSh2tVbuH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the 'width' of images - it should be the same for all\n",
        "resolutions[:, 1]"
      ],
      "metadata": {
        "id": "3f_I71JzXD74"
      },
      "id": "3f_I71JzXD74",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the resolution\n",
        "\n",
        "import plotly.express as px\n",
        "\n",
        "# Create a scatter plot figure with plotly\n",
        "fig = px.scatter(x=resolutions[:, 1], y=resolutions[:, 0], title=\"Distribution of Image Resolutions\")\n",
        "\n",
        "# Customize the plot\n",
        "fig.update_layout(\n",
        "    xaxis_title=\"Width (pixels)\",\n",
        "    yaxis_title=\"Height (pixels)\",\n",
        "    showlegend=False,\n",
        "    hovermode=\"closest\",\n",
        "    width=800,\n",
        "    height=600,\n",
        "    margin=dict(l=50, r=50, b=50, t=50, pad=4)\n",
        ")\n",
        "\n",
        "# Show the plot\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "jUjeJKtuVV6g"
      },
      "id": "jUjeJKtuVV6g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A.2 Analyze the brightness and colour distribution of all images\n",
        "\n",
        "Calculate greyscale representations, channel distribution (Red, Green, Blue) and real colour distribution"
      ],
      "metadata": {
        "id": "WPGjnPrMiEZL"
      },
      "id": "WPGjnPrMiEZL"
    },
    {
      "cell_type": "code",
      "source": [
        "# Greyscale analysis: calculate the color distribution from 0-255\n",
        "\n",
        "color_distributions = []\n",
        "\n",
        "# Iterate over each image file in each subdirectory\n",
        "for dirpath, dirnames, filenames in os.walk(root_path):\n",
        "    for filename in filenames:\n",
        "        if filename.lower().endswith(('.png')):\n",
        "            # Load the image file using OpenCV\n",
        "            img_path = os.path.join(dirpath, filename)\n",
        "            img = cv2.imread(img_path)\n",
        "\n",
        "            # Extract the color distribution of the image\n",
        "            color_distribution = np.bincount(img.flatten(), minlength=256)\n",
        "            color_distributions.append(color_distribution)\n",
        "\n",
        "# Convert the lists to numpy arrays\n",
        "color_distributions = np.array(color_distributions)"
      ],
      "metadata": {
        "id": "m375IKacby3a"
      },
      "id": "m375IKacby3a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objs as go\n",
        "\n",
        "# Create a list of bar traces for each color value\n",
        "traces = []\n",
        "for i in range(256):\n",
        "    # Create an RGB color string for grayscale (e.g., rgb(0,0,0) for 0, rgb(255,255,255) for 255)\n",
        "    color = f\"rgb({i}, {i}, {i})\"\n",
        "    traces.append(go.Bar(x=np.arange(len(color_distributions)), y=color_distributions[:, i], name=str(i), marker_color=color))\n",
        "\n",
        "# Create the figure and set the layout\n",
        "fig = go.Figure(data=traces)\n",
        "fig.update_layout(title=\"Grayscale Tone Distributions for Each Image\", xaxis_title=\"Image Index\", yaxis_title=\"Number of Pixels\", barmode=\"stack\")\n",
        "# Show the plot\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "q0P6a9OPblL7"
      },
      "id": "q0P6a9OPblL7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A.3 Analyze the colour composition of website screenshots"
      ],
      "metadata": {
        "id": "t4sr_Y6oAO_O"
      },
      "id": "t4sr_Y6oAO_O"
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "# This list will store color distributions for each channel (B, G, R) for each image\n",
        "# It will be a list of lists, where each inner list contains three arrays (one for each channel)\n",
        "channel_color_distributions = []\n",
        "\n",
        "# Iterate over each image file in each subdirectory\n",
        "for dirpath, dirnames, filenames in os.walk(root_path):\n",
        "    for filename in filenames:\n",
        "        if filename.lower().endswith(('.png')):\n",
        "            # Load the image file using OpenCV\n",
        "            img_path = os.path.join(dirpath, filename)\n",
        "            img = cv2.imread(img_path) # OpenCV reads images as BGR by default\n",
        "\n",
        "            if img is not None:\n",
        "                # Split the image into its B, G, R channels\n",
        "                b_channel, g_channel, r_channel = cv2.split(img)\n",
        "\n",
        "                # Calculate color distribution for each channel\n",
        "                b_hist = np.bincount(b_channel.flatten(), minlength=256)\n",
        "                g_hist = np.bincount(g_channel.flatten(), minlength=256)\n",
        "                r_hist = np.bincount(r_channel.flatten(), minlength=256)\n",
        "\n",
        "                channel_color_distributions.append([b_hist, g_hist, r_hist])\n",
        "\n",
        "# Convert the list of lists to a NumPy array for easier manipulation\n",
        "# The shape will be (num_images, 3, 256) where 3 is for B, G, R channels\n",
        "channel_color_distributions = np.array(channel_color_distributions)"
      ],
      "metadata": {
        "id": "8X9OImx0ZqUp"
      },
      "id": "8X9OImx0ZqUp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b68bc61"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "# Calculate the total pixel count for each channel for each image\n",
        "# The shape of channel_color_distributions is (num_images, 3, 256)\n",
        "# Summing along the last axis (axis=2) gives us (num_images, 3) total pixel counts\n",
        "total_channel_pixels = np.sum(channel_color_distributions, axis=2)\n",
        "\n",
        "# Separate the total pixel counts for each channel\n",
        "total_b_pixels = total_channel_pixels[:, 0]\n",
        "total_g_pixels = total_channel_pixels[:, 1]\n",
        "total_r_pixels = total_channel_pixels[:, 2]\n",
        "\n",
        "# Create a list of image indices for the x-axis\n",
        "image_indices = [f\"Image {i+1}\" for i in range(len(channel_color_distributions))]\n",
        "\n",
        "# Create traces for each channel, with each image on the x-axis\n",
        "trace_b = go.Bar(x=image_indices, y=total_b_pixels, name='R', marker_color='blue')\n",
        "trace_g = go.Bar(x=image_indices, y=total_g_pixels, name='G', marker_color='green')\n",
        "trace_r = go.Bar(x=image_indices, y=total_r_pixels, name='B', marker_color='red')\n",
        "\n",
        "# Create the figure and set the layout\n",
        "fig = go.Figure(data=[trace_b, trace_g, trace_r])\n",
        "fig.update_layout(\n",
        "    title=\"Total RGB pixel counts \",\n",
        "    xaxis_title=\"Image\",\n",
        "    yaxis_title=\"Total Number of Pixels\",\n",
        "    barmode='stack' # Stack the bars for each image\n",
        ")\n",
        "\n",
        "# Show the plot\n",
        "fig.show()"
      ],
      "id": "7b68bc61",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1a1fbf2"
      },
      "source": [
        "image_data = []\n",
        "\n",
        "for dirpath, dirnames, filenames in os.walk(root_path):\n",
        "    for filename in filenames:\n",
        "        if filename.lower().endswith(('.png')):\n",
        "            img_path = os.path.join(dirpath, filename)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is not None:\n",
        "                image_data.append(img)\n",
        "\n",
        "print(f\"Loaded {len(image_data)} images. First image shape: {image_data[0].shape}\")"
      ],
      "id": "d1a1fbf2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54f18a6e"
      },
      "source": [
        "def categorize_color(b, g, r):\n",
        "    # Convert BGR to RGB for easier human-readable categorization\n",
        "    rgb = (r, g, b)\n",
        "\n",
        "    # Grayscale check (near-equal R, G, B values)\n",
        "    # Cast to np.int16 to prevent overflow warnings during subtraction\n",
        "    if abs(np.int16(r) - np.int16(g)) < 10 and abs(np.int16(r) - np.int16(b)) < 10 and abs(np.int16(g) - np.int16(b)) < 10:\n",
        "        if r > 200: return 'White'\n",
        "        if r < 50: return 'Black'\n",
        "        return 'Gray'\n",
        "\n",
        "    # Primary/Secondary Color checks\n",
        "    if r > 200 and g < 100 and b < 100: return 'Red'\n",
        "    if r < 100 and g > 200 and b < 100: return 'Green'\n",
        "    if r < 100 and g < 100 and b > 200: return 'Blue'\n",
        "\n",
        "    if r > 200 and g > 200 and b < 100: return 'Yellow'\n",
        "    if r < 100 and g > 200 and b > 200: return 'Cyan'\n",
        "    if r > 200 and g < 100 and b > 200: return 'Magenta'\n",
        "\n",
        "    # Other common shades (simplified)\n",
        "    if r > 150 and g > 100 and b < 100: return 'Orange'\n",
        "    if r > 100 and g < 100 and b < 50: return 'Brown'\n",
        "\n",
        "    return 'Other'"
      ],
      "id": "54f18a6e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4df28125"
      },
      "source": [
        "# WARNING: THIS TAKES LONG TIME (30-45 minutes)\n",
        "# YOU CAN FOLLOW THE PROGRESS ON THE PROGRESS BAR, BELOW\n",
        "\n",
        "from collections import defaultdict\n",
        "from tqdm.notebook import tqdm # Import tqdm for progress bar\n",
        "\n",
        "image_color_counts = []\n",
        "color_categories = ['White', 'Black', 'Gray', 'Red', 'Green', 'Blue', 'Yellow', 'Cyan', 'Magenta', 'Orange', 'Brown', 'Other']\n",
        "\n",
        "# Wrap the image_data iteration with tqdm for a progress bar\n",
        "for img_index, img in tqdm(enumerate(image_data), total=len(image_data), desc=\"Processing Images\"):\n",
        "    current_image_counts = defaultdict(int)\n",
        "    # Reshape image to a list of pixels (height * width, 3)\n",
        "    pixels = img.reshape(-1, 3)\n",
        "\n",
        "    for pixel in pixels:\n",
        "        b, g, r = pixel # OpenCV stores as BGR\n",
        "        category = categorize_color(b, g, r)\n",
        "        current_image_counts[category] += 1\n",
        "\n",
        "    # Convert defaultdict to a regular dict and append to the list\n",
        "    # Ensure all categories are present, even if their count is 0\n",
        "    full_counts = {category: current_image_counts[category] for category in color_categories}\n",
        "    image_color_counts.append(full_counts)\n",
        "\n",
        "print(f\"Processed color counts for {len(image_color_counts)} images.\")\n",
        "# print(image_color_counts[0]) # Print first image's color counts to verify"
      ],
      "id": "4df28125",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check whether the image_color_counts includes all images (62) and all categories (12)\n",
        "len(image_color_counts[0])"
      ],
      "metadata": {
        "id": "101kK-tm-Z_I"
      },
      "id": "101kK-tm-Z_I",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29d4bb5d"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "\n",
        "# Assuming image_color_counts is a list of dictionaries, and color_categories is defined\n",
        "# (both populated from previous steps)\n",
        "\n",
        "# Create a list of image labels for the x-axis\n",
        "image_labels = [f'Image {i+1}' for i in range(len(image_color_counts))]\n",
        "\n",
        "# Define a mapping from category names to representative colors for plotting\n",
        "color_map = {\n",
        "    'White': 'rgb(255, 255, 255)',\n",
        "    'Black': 'rgb(0, 0, 0)',\n",
        "    'Gray': 'rgb(128, 128, 128)',\n",
        "    'Red': 'rgb(255, 0, 0)',\n",
        "    'Green': 'rgb(0, 255, 0)',\n",
        "    'Blue': 'rgb(0, 0, 255)',\n",
        "    'Yellow': 'rgb(255, 255, 0)',\n",
        "    'Cyan': 'rgb(0, 255, 255)',\n",
        "    'Magenta': 'rgb(255, 0, 255)',\n",
        "    'Orange': 'rgb(255, 165, 0)',\n",
        "    'Brown': 'rgb(165, 42, 42)',\n",
        "    'Other': 'rgb(255, 224, 200)' # A neutral color for 'Other'\n",
        "}\n",
        "\n",
        "traces = []\n",
        "\n",
        "# Iterate through each color category to create a trace for it\n",
        "for category in color_categories:\n",
        "    # Extract the counts for the current category across all images\n",
        "    counts_for_category = [img_counts[category] for img_counts in image_color_counts]\n",
        "\n",
        "    # Create a bar trace for this category\n",
        "    traces.append(go.Bar(\n",
        "        x=image_labels,\n",
        "        y=counts_for_category,\n",
        "        name=category,\n",
        "        marker_color=color_map.get(category, 'rgb(150, 150, 150)') # Use defined color or a default grey\n",
        "    ))\n",
        "\n",
        "# Create the figure and set the layout\n",
        "fig = go.Figure(data=traces)\n",
        "fig.update_layout(\n",
        "    title=\"Distribution of colors (categorized w-o) across all images\",\n",
        "    xaxis_title=\"Image\",\n",
        "    yaxis_title=\"Number of Pixels\",\n",
        "    barmode='stack', # Stack the bars for each image\n",
        "    hovermode='x unified' # Show hover info for all stacks at once\n",
        ")\n",
        "\n",
        "# Show the plot\n",
        "fig.show()"
      ],
      "id": "29d4bb5d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## B. Discourse Analysis"
      ],
      "metadata": {
        "id": "tRv48s-JboPN"
      },
      "id": "tRv48s-JboPN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### B.1 Close reading one document\n",
        "(we will consider one website as a 'document')"
      ],
      "metadata": {
        "id": "WV5qWUIO1xA2"
      },
      "id": "WV5qWUIO1xA2"
    },
    {
      "cell_type": "code",
      "source": [
        "# list all unique domain names\n",
        "df['domain'].unique()"
      ],
      "metadata": {
        "id": "29umRTewbnDU"
      },
      "id": "29umRTewbnDU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract all rows (lines) where the value of 'domain' is 'lancashire.gov.uk'\n",
        "df[df['domain'] == 'lancashire.gov.uk']"
      ],
      "metadata": {
        "id": "a5mBBe-ncnfz"
      },
      "id": "a5mBBe-ncnfz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# then combine these into a list of pages\n",
        "document = df[df['domain'] == 'lancashire.gov.uk']['text'].tolist()"
      ],
      "metadata": {
        "id": "7SfU5XXfdN7l"
      },
      "id": "7SfU5XXfdN7l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document"
      ],
      "metadata": {
        "id": "ksw6zTgodjqL"
      },
      "id": "ksw6zTgodjqL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_document = []\n",
        "for i in document:\n",
        "  j = i.replace('\\n', ' ').replace('\\r', '')\n",
        "  clean_document.append(j)"
      ],
      "metadata": {
        "id": "_YEFxHo-ePV7"
      },
      "id": "_YEFxHo-ePV7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_document"
      ],
      "metadata": {
        "id": "kyc5LLlAeebS"
      },
      "id": "kyc5LLlAeebS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### B.2 Topic Modelling"
      ],
      "metadata": {
        "id": "inCepASp67ru"
      },
      "id": "inCepASp67ru"
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.feature_extraction.text as text\n",
        "\n",
        "# min_df: ignore words occurring in fewer than `n` documents\n",
        "# stop_words: ignore very common words (\"the\", \"and\", \"or\", \"to\", ...)\n",
        "vec = text.CountVectorizer(lowercase=True, min_df=100, stop_words='english')\n",
        "dtm = vec.fit_transform(df['text'])"
      ],
      "metadata": {
        "id": "Gja1IgP932EG"
      },
      "id": "Gja1IgP932EG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Shape of document-term matrix: {dtm.shape}. '\n",
        "      f'Number of tokens {dtm.sum()}')"
      ],
      "metadata": {
        "id": "MEDoEJ1W4BfX"
      },
      "id": "MEDoEJ1W4BfX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.decomposition as decomposition\n",
        "NUM_TOPICS = 10\n",
        "lda_model = decomposition.LatentDirichletAllocation(\n",
        "    n_components=NUM_TOPICS, learning_method='online', random_state=1)\n",
        "lda_Z = lda_model.fit_transform(dtm)\n",
        "print(lda_Z.shape)  # (NO_DOCUMENTS, NO_TOPICS)"
      ],
      "metadata": {
        "id": "gMYvBI_h6UNh"
      },
      "id": "gMYvBI_h6UNh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_topic_distributions = lda_model.fit_transform(dtm)"
      ],
      "metadata": {
        "id": "b2jaGSW84Zcz"
      },
      "id": "b2jaGSW84Zcz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_n=10\n",
        "for idx, topic in enumerate(lda_model.components_):\n",
        "  print(\"Topic %d:\" % (idx))\n",
        "  print([(vec.get_feature_names_out()[i], topic[i])\n",
        "  for i in topic.argsort()[:-top_n - 1:-1]])"
      ],
      "metadata": {
        "id": "Whj_h2dd8U65"
      },
      "id": "Whj_h2dd8U65",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_top_words = 12\n",
        "no_top_documents = 5\n",
        "lda_H = lda_model.components_\n",
        "tf_feature_names = vec.get_feature_names_out()\n",
        "\n",
        "def display_topics(H, Z, feature_names, docs, no_top_words, no_top_documents):\n",
        "    for idx, topic in enumerate(H):\n",
        "        print(\"Topic %d:\" % (idx))\n",
        "        print(\"KEYWORDS\", \" \".join([feature_names[i]\n",
        "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
        "        top_doc_indices = np.argsort( Z[:,\n",
        "                                        idx] )[::-1][0:no_top_documents]\n",
        "        # good for checking which documents are the most characteristic for certain topics\n",
        "        for doc_index in top_doc_indices:\n",
        "            print(\"TOP DOCS\", docs[doc_index])\n",
        "\n",
        "display_topics(lda_H, lda_Z, tf_feature_names, df['url'].tolist(), no_top_words, no_top_documents)"
      ],
      "metadata": {
        "id": "gj7pbaiH8_IZ"
      },
      "id": "gj7pbaiH8_IZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### B.5 Word2Vec model"
      ],
      "metadata": {
        "id": "8nURhyHN8ymX"
      },
      "id": "8nURhyHN8ymX"
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "id": "4YrTkLDz9hjC"
      },
      "id": "4YrTkLDz9hjC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "id": "5wGmUzqJ56fz"
      },
      "id": "5wGmUzqJ56fz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bca25ef7-5a19-41e3-a199-bdde7304e575",
      "metadata": {
        "id": "bca25ef7-5a19-41e3-a199-bdde7304e575"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# X is a list of tokenized texts (i.e. list of lists of tokens)\n",
        "X = [word_tokenize(item) for item in df.text.tolist()]\n",
        "#print(X[0:3])\n",
        "model = gensim.models.Word2Vec(X, min_count=6, vector_size=200) # min_count: how many times a word appears in the corpus; size: number of dimensions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now try out some keywords that may be characteristic in the corpus on heritage homes, such as 'castle', 'garden', 'party', 'princess'; try also words related to less obvious themes, like 'servant'\n",
        "\n",
        "You can ask for 'negative' or 'positive' similarity, and explore how these bring up terms that are opposite to the meaning in a variety of ways."
      ],
      "metadata": {
        "id": "YGmA045M5tt8"
      },
      "id": "YGmA045M5tt8"
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.most_similar(positive=[\"castle\"], topn=12)"
      ],
      "metadata": {
        "id": "QS_aLSZc87XP"
      },
      "id": "QS_aLSZc87XP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.most_similar(positive=[\"garden\"], topn=12)"
      ],
      "metadata": {
        "id": "ornUSbnUl9fN"
      },
      "id": "ornUSbnUl9fN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.most_similar(positive=[\"servant\"], topn=12)"
      ],
      "metadata": {
        "id": "HiDkL_DB5rSN"
      },
      "id": "HiDkL_DB5rSN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.most_similar(negative=[\"princess\"], topn=12)"
      ],
      "metadata": {
        "id": "v6u1Ns3T5oI6"
      },
      "id": "v6u1Ns3T5oI6",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}