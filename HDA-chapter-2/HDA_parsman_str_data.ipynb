{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "02cbadff-c1c8-481c-bf8e-2675d6613a36",
      "metadata": {
        "id": "02cbadff-c1c8-481c-bf8e-2675d6613a36"
      },
      "source": [
        "### Humanities Data Analysis: Case studies with Python\n",
        "--------------------------------------------------\n",
        "Folgert Karsdorp, Mike Kestemont & Allen Riddell\n",
        "Chapter 2: Parsing and Manipulating Structured Data\n",
        "\n",
        "https://www.humanitiesdataanalysis.org/getting-data/notebook.html#plain-text"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y5mT2DqeVAQl"
      },
      "id": "Y5mT2DqeVAQl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yg4A-c-ZT-w0"
      },
      "source": [
        "!git clone https://github.com/jazoza/cultural-data-analysis.git"
      ],
      "id": "Yg4A-c-ZT-w0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folderpath='cultural-data-analysis/HDA-chapter-2/'"
      ],
      "metadata": {
        "id": "T_Sa-6g3V6k_"
      },
      "id": "T_Sa-6g3V6k_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16bade3d-af77-4c12-a508-e6227aa78835",
      "metadata": {
        "id": "16bade3d-af77-4c12-a508-e6227aa78835"
      },
      "outputs": [],
      "source": [
        "import tarfile\n",
        "\n",
        "tf = tarfile.open(folderpath+'data/folger.tar.gz', 'r')\n",
        "tf.extractall('data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "893c96d7-aff2-46fa-8891-09c2d20c8cba",
      "metadata": {
        "id": "893c96d7-aff2-46fa-8891-09c2d20c8cba"
      },
      "outputs": [],
      "source": [
        "file_path = folderpath+'data/folger/txt/1H4.txt'\n",
        "stream = open(file_path)\n",
        "contents = stream.read()\n",
        "stream.close()\n",
        "\n",
        "print(contents[:300])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d092a6e-6945-4e1c-8e21-3f0381565330",
      "metadata": {
        "id": "4d092a6e-6945-4e1c-8e21-3f0381565330"
      },
      "outputs": [],
      "source": [
        "with open(file_path) as stream:\n",
        "    contents = stream.read()\n",
        "\n",
        "print(contents[:300])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8fd274f-12d2-49f6-a535-df7719490191",
      "metadata": {
        "id": "a8fd274f-12d2-49f6-a535-df7719490191"
      },
      "outputs": [],
      "source": [
        "with open(folderpath+'data/anna-karenina.txt', encoding='koi8-r') as stream:\n",
        "    # Use stream.readline() to retrieve the next line from a file,\n",
        "    # in this case the 1st one:\n",
        "    line = stream.readline()\n",
        "\n",
        "print(line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73bf9363-a1fe-4375-8a29-2fd6eb97fca9",
      "metadata": {
        "id": "73bf9363-a1fe-4375-8a29-2fd6eb97fca9"
      },
      "outputs": [],
      "source": [
        "csv_file = folderpath+'data/folger_shakespeare_collection.csv'\n",
        "with open(csv_file) as stream:\n",
        "    # call stream.readlines() to read all lines in the CSV file as a list.\n",
        "    lines = stream.readlines()\n",
        "\n",
        "print(lines[:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "975d3ae4-2315-4d29-b76b-b54fbee2c231",
      "metadata": {
        "id": "975d3ae4-2315-4d29-b76b-b54fbee2c231"
      },
      "outputs": [],
      "source": [
        "entries = []\n",
        "for line in open(csv_file):\n",
        "    entries.append(line.strip().split(','))\n",
        "\n",
        "for entry in entries[:3]:\n",
        "    print(entry)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a7757a3-ae23-4591-b5d2-c0fb3694eb2f",
      "metadata": {
        "id": "8a7757a3-ae23-4591-b5d2-c0fb3694eb2f"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "entries = []\n",
        "with open(csv_file) as stream:\n",
        "    reader = csv.reader(stream, delimiter=',')\n",
        "    for fname, author, title, editor, publisher, pubplace, date in reader:\n",
        "        entries.append((fname, title))\n",
        "\n",
        "for entry in entries[:5]:\n",
        "    print(entry)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d661257-44c6-406b-b23d-6c0225f983ef",
      "metadata": {
        "id": "3d661257-44c6-406b-b23d-6c0225f983ef"
      },
      "outputs": [],
      "source": [
        "entries = []\n",
        "with open(csv_file) as stream:\n",
        "    reader = csv.reader(stream, delimiter=',')\n",
        "    for fname, _, title, *_ in reader:\n",
        "        entries.append((fname, title))\n",
        "\n",
        "for entry in entries[:5]:\n",
        "    print(entry)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64df8800-30ae-40bf-898e-80568bdeadd6",
      "metadata": {
        "id": "64df8800-30ae-40bf-898e-80568bdeadd6"
      },
      "outputs": [],
      "source": [
        "a, _, c, _, _ = range(5)\n",
        "print(a, c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19ef8b93-1853-4ac8-be9f-536df3bb1bd6",
      "metadata": {
        "id": "19ef8b93-1853-4ac8-be9f-536df3bb1bd6"
      },
      "outputs": [],
      "source": [
        "a, *l = range(5)\n",
        "print(a, l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acc68fd1-11e1-4678-8617-41190931dce2",
      "metadata": {
        "id": "acc68fd1-11e1-4678-8617-41190931dce2"
      },
      "outputs": [],
      "source": [
        "seq = range(5)\n",
        "a, l = seq[0], seq[1:]\n",
        "print(a, l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12fc3559-9135-4b51-aebc-140d4184d007",
      "metadata": {
        "id": "12fc3559-9135-4b51-aebc-140d4184d007"
      },
      "outputs": [],
      "source": [
        "a, *l, b = range(5)\n",
        "print(a, l, b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7753b70e-c696-461f-9541-69677786c4d9",
      "metadata": {
        "id": "7753b70e-c696-461f-9541-69677786c4d9"
      },
      "outputs": [],
      "source": [
        "entries = []\n",
        "\n",
        "with open(csv_file) as stream:\n",
        "    reader = csv.DictReader(stream, delimiter=',')\n",
        "    for row in reader:\n",
        "        entries.append(row)\n",
        "\n",
        "for entry in entries[:5]:\n",
        "    print(entry['fname'], entry['title'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be7f1374-5590-4ea3-b477-e20f6a961a9b",
      "metadata": {
        "id": "be7f1374-5590-4ea3-b477-e20f6a961a9b"
      },
      "outputs": [],
      "source": [
        "!pip install pypdf2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "337c3c27-4791-4ecf-a824-b240e3c43049",
      "metadata": {
        "id": "337c3c27-4791-4ecf-a824-b240e3c43049"
      },
      "outputs": [],
      "source": [
        "import PyPDF2 as PDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e2e002a-18eb-4783-b10e-016b8b3a5043",
      "metadata": {
        "id": "7e2e002a-18eb-4783-b10e-016b8b3a5043"
      },
      "outputs": [],
      "source": [
        "file_path = folderpath+'data/folger/pdf/1H4.pdf'\n",
        "pdf = PDF.PdfReader(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cae66b3-64cb-43b1-83fd-7f3d76464407",
      "metadata": {
        "id": "7cae66b3-64cb-43b1-83fd-7f3d76464407"
      },
      "outputs": [],
      "source": [
        "n_pages = len(pdf.pages)\n",
        "print(f'PDF has {n_pages} pages.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d009224b-62d6-4408-8ec3-67c08418be1a",
      "metadata": {
        "id": "d009224b-62d6-4408-8ec3-67c08418be1a"
      },
      "outputs": [],
      "source": [
        "page = pdf.pages[1]\n",
        "content = page.extract_text()\n",
        "print(content[:150])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07f0efc1-a569-4fed-ae30-80c7b79bbdd8",
      "metadata": {
        "id": "07f0efc1-a569-4fed-ae30-80c7b79bbdd8"
      },
      "outputs": [],
      "source": [
        "def pdf2txt(fname, page_numbers=None, concatenate=False):\n",
        "    \"\"\"Convert text from a PDF file into a string or list of strings.\n",
        "\n",
        "    Arguments:\n",
        "        fname: a string pointing to the filename of the PDF file\n",
        "        page_numbers: an integer or sequence of integers pointing to the\n",
        "            pages to extract. If None (default), all pages are extracted.\n",
        "        concatenate: a boolean indicating whether to concatenate the\n",
        "            extracted pages into a single string. When False, a list of\n",
        "            strings is returned.\n",
        "\n",
        "    Returns:\n",
        "        A string or list of strings representing the text extracted\n",
        "        from the supplied PDF file.\n",
        "\n",
        "    \"\"\"\n",
        "    pdf = PDF.PdfReader(file_path)\n",
        "    if page_numbers is None:\n",
        "        page_numbers = range(len(pdf.pages))\n",
        "    elif isinstance(page_numbers, int):\n",
        "        page_numbers = [page_numbers]\n",
        "    texts = [pdf.pages[n].extract_text() for n in page_numbers]\n",
        "    return '\\n'.join(texts) if concatenate else texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc581c85-6f9d-4920-8748-2ff29bde0ad0",
      "metadata": {
        "id": "bc581c85-6f9d-4920-8748-2ff29bde0ad0"
      },
      "outputs": [],
      "source": [
        "text = pdf2txt(file_path, concatenate=True)\n",
        "sample = pdf2txt(file_path, page_numbers=[1, 4, 9])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample)"
      ],
      "metadata": {
        "id": "HkMT6g0DYHQq"
      },
      "id": "HkMT6g0DYHQq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab1ce2f5-409c-4c0a-9714-8fe1add7e229",
      "metadata": {
        "id": "ab1ce2f5-409c-4c0a-9714-8fe1add7e229"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "line = {\n",
        "    'line_id': 12664,\n",
        "    'play_name': 'Alls well that ends well',\n",
        "    'speech_number': 1,\n",
        "    'line_number': '1.1.1',\n",
        "    'speaker': 'COUNTESS',\n",
        "    'text_entry': 'In delivering my son from me, I bury a second husband.'\n",
        "}\n",
        "\n",
        "print(json.dumps(line))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8daaf6b-fb80-4c63-b85f-46404727225b",
      "metadata": {
        "id": "f8daaf6b-fb80-4c63-b85f-46404727225b"
      },
      "outputs": [],
      "source": [
        "with open('shakespeare.json', 'w') as f:\n",
        "    json.dump(line, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "321397b0-952b-4415-863e-42595ccc1ea3",
      "metadata": {
        "id": "321397b0-952b-4415-863e-42595ccc1ea3"
      },
      "outputs": [],
      "source": [
        "with open(folderpath+'data/macbeth.json') as f:\n",
        "    data = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f7b98b3-59dc-4847-9273-b2b3c41bb132",
      "metadata": {
        "id": "3f7b98b3-59dc-4847-9273-b2b3c41bb132"
      },
      "outputs": [],
      "source": [
        "print(data[3:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6e55de1-a79a-4cc5-af23-e2259aee71e2",
      "metadata": {
        "id": "e6e55de1-a79a-4cc5-af23-e2259aee71e2"
      },
      "outputs": [],
      "source": [
        "import collections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48844798-4b9f-4325-8d8d-0b7cd82d9302",
      "metadata": {
        "id": "48844798-4b9f-4325-8d8d-0b7cd82d9302"
      },
      "outputs": [],
      "source": [
        "languages = collections.Counter()\n",
        "for entry in data:\n",
        "    languages[entry['lang']] += 1\n",
        "\n",
        "print(languages.most_common())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01833d2b-0967-4286-b75a-9cf8da7c57a8",
      "metadata": {
        "id": "01833d2b-0967-4286-b75a-9cf8da7c57a8"
      },
      "outputs": [],
      "source": [
        "with open(folderpath+'data/sonnets/18.xml') as stream:\n",
        "    xml = stream.read()\n",
        "\n",
        "print(xml)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bbc6d9d-d7ec-4b0e-a389-15d3f857b4bb",
      "metadata": {
        "id": "2bbc6d9d-d7ec-4b0e-a389-15d3f857b4bb"
      },
      "outputs": [],
      "source": [
        "import lxml.etree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5215492e-95ca-4f35-916b-3280399bb6ac",
      "metadata": {
        "id": "5215492e-95ca-4f35-916b-3280399bb6ac"
      },
      "outputs": [],
      "source": [
        "tree = lxml.etree.parse(folderpath+'data/sonnets/18.xml')\n",
        "print(tree)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60636756-6b8f-416d-b16f-53a37410c2e7",
      "metadata": {
        "id": "60636756-6b8f-416d-b16f-53a37410c2e7"
      },
      "outputs": [],
      "source": [
        "# decoding is needed to transform the bytes object into an actual string\n",
        "print(lxml.etree.tostring(tree).decode())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95674ee5-59b3-4a8f-99dd-2d51dd8a66fa",
      "metadata": {
        "id": "95674ee5-59b3-4a8f-99dd-2d51dd8a66fa"
      },
      "outputs": [],
      "source": [
        "for rhyme in tree.iterfind('//rhyme'):\n",
        "    print(f'element: {rhyme.tag} -> {rhyme.text}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c317e36-bb31-4e46-aba6-2350b6df7fb3",
      "metadata": {
        "id": "6c317e36-bb31-4e46-aba6-2350b6df7fb3"
      },
      "outputs": [],
      "source": [
        "root = tree.getroot()\n",
        "print(root.tag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5a0d187-8311-4b90-8471-122aff6ee9f6",
      "metadata": {
        "id": "c5a0d187-8311-4b90-8471-122aff6ee9f6"
      },
      "outputs": [],
      "source": [
        "print(root.attrib['year'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aeadb3ec-2dc0-4bfb-9b7c-faa2f7de520f",
      "metadata": {
        "id": "aeadb3ec-2dc0-4bfb-9b7c-faa2f7de520f"
      },
      "outputs": [],
      "source": [
        "print(len(root))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "563e4d49-44c4-4197-82bd-2f9d0f83b0de",
      "metadata": {
        "id": "563e4d49-44c4-4197-82bd-2f9d0f83b0de"
      },
      "outputs": [],
      "source": [
        "children = [child.tag for child in root]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc8b88aa-70c2-4fdd-a228-77f158dbdc5e",
      "metadata": {
        "id": "dc8b88aa-70c2-4fdd-a228-77f158dbdc5e"
      },
      "outputs": [],
      "source": [
        "print('\\n'.join(child.text or '' for child in root))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c72cb4cd-38f6-4941-b546-114efd3c47b0",
      "metadata": {
        "id": "c72cb4cd-38f6-4941-b546-114efd3c47b0"
      },
      "outputs": [],
      "source": [
        "print(''.join(root[0].itertext()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6dfded5-2e79-4003-bd06-93f01b697727",
      "metadata": {
        "id": "d6dfded5-2e79-4003-bd06-93f01b697727"
      },
      "outputs": [],
      "source": [
        "for node in root:\n",
        "    if node.tag == 'line':\n",
        "        print(f\"line {node.attrib['n']: >2}: {''.join(node.itertext())}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1464839-05d7-404c-abcb-ce6b0fbb3505",
      "metadata": {
        "id": "a1464839-05d7-404c-abcb-ce6b0fbb3505"
      },
      "outputs": [],
      "source": [
        "with open(folderpath+'data/sonnets/116.txt') as stream:\n",
        "    text = stream.read()\n",
        "\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bc047ff-2ce0-4aaa-a9fb-9dd3133b5b17",
      "metadata": {
        "id": "5bc047ff-2ce0-4aaa-a9fb-9dd3133b5b17"
      },
      "outputs": [],
      "source": [
        "root = lxml.etree.Element('sonnet')\n",
        "root.attrib['author'] = 'William Shakespeare'\n",
        "root.attrib['year'] = '1609'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39590c54-20b5-4628-adc3-c532b2bec11f",
      "metadata": {
        "id": "39590c54-20b5-4628-adc3-c532b2bec11f"
      },
      "outputs": [],
      "source": [
        "tree = lxml.etree.ElementTree(root)\n",
        "stringified = lxml.etree.tostring(tree)\n",
        "print(stringified)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0c3692c-0308-4cd7-b183-001a4d1b6940",
      "metadata": {
        "id": "d0c3692c-0308-4cd7-b183-001a4d1b6940"
      },
      "outputs": [],
      "source": [
        "print(type(stringified))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd9163a4-a1ec-4263-ab6b-b35d01883e9c",
      "metadata": {
        "id": "bd9163a4-a1ec-4263-ab6b-b35d01883e9c"
      },
      "outputs": [],
      "source": [
        "print(stringified.decode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dfd47d7-f871-4b4f-bcd6-4c01f8b7b0cb",
      "metadata": {
        "id": "4dfd47d7-f871-4b4f-bcd6-4c01f8b7b0cb"
      },
      "outputs": [],
      "source": [
        "for nb, line in enumerate(open(folderpath+'data/sonnets/116.txt')):\n",
        "    node = lxml.etree.Element('line')\n",
        "    node.attrib['n'] = str(nb + 1)\n",
        "    node.text = line.strip()\n",
        "    root.append(node)\n",
        "    # voltas typically, but not always occur between the octave and sextet\n",
        "    if nb == 8:\n",
        "        node = lxml.etree.Element('volta')\n",
        "        root.append(node)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44201841-6110-46cd-9cf0-41d0fa0aa77a",
      "metadata": {
        "id": "44201841-6110-46cd-9cf0-41d0fa0aa77a"
      },
      "outputs": [],
      "source": [
        "print(lxml.etree.tostring(tree, pretty_print=True).decode())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7971859-80d2-44cb-a4aa-16d2bb796cbb",
      "metadata": {
        "id": "d7971859-80d2-44cb-a4aa-16d2bb796cbb"
      },
      "outputs": [],
      "source": [
        "# Loop over all nodes in the tree\n",
        "for node in root:\n",
        "    # Leave the volta node alone. A continue statement instructs\n",
        "    # Python to move on to the next item in the loop.\n",
        "    if node.tag == 'volta':\n",
        "        continue\n",
        "    # We chop off and store verse-final punctuation:\n",
        "    punctuation = ''\n",
        "    if node.text[-1] in ',:;.':\n",
        "        punctuation = node.text[-1]\n",
        "        node.text = node.text[:-1]\n",
        "    # Make a list of words using the split method\n",
        "    words = node.text.split()\n",
        "    # We split rhyme words and other words:\n",
        "    other_words, rhyme = words[:-1], words[-1]\n",
        "    # Replace the node's text with all text except the rhyme word\n",
        "    node.text = ' '.join(other_words) + ' '\n",
        "    # We create the rhyme element, with punctuation (if any) in its tail\n",
        "    elt = lxml.etree.Element('rhyme')\n",
        "    elt.text = rhyme\n",
        "    elt.tail = punctuation\n",
        "    # We add the rhyme to the line:\n",
        "    node.append(elt)\n",
        "\n",
        "tree = lxml.etree.ElementTree(root)\n",
        "print(lxml.etree.tostring(tree, pretty_print=True).decode())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6b1710d-d4a2-4053-bf84-1ab5476f6038",
      "metadata": {
        "id": "b6b1710d-d4a2-4053-bf84-1ab5476f6038"
      },
      "outputs": [],
      "source": [
        "with open(folderpath+'data/sonnets/116.xml', 'w') as f:\n",
        "    f.write(\n",
        "        lxml.etree.tostring(\n",
        "            root, xml_declaration=True, pretty_print=True, encoding='utf-8').decode())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e9d26b6-8144-4b08-aab6-7bc56496c871",
      "metadata": {
        "id": "2e9d26b6-8144-4b08-aab6-7bc56496c871"
      },
      "outputs": [],
      "source": [
        "root = lxml.etree.Element('sonnet')\n",
        "# Add an author attribute to the root node\n",
        "root.attrib['author'] = 'William Shakespeare'\n",
        "# Add a year attribute to the root node\n",
        "root.attrib['year'] = '1609'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abb89bb0-18ae-4e95-9acc-535f695afa48",
      "metadata": {
        "id": "abb89bb0-18ae-4e95-9acc-535f695afa48"
      },
      "outputs": [],
      "source": [
        "for nb, line in enumerate(open(folderpath+'data/sonnets/116.txt')):\n",
        "    line_node = lxml.etree.Element('line')\n",
        "    # Add a line number attribute to each line node\n",
        "    line_node.attrib['n'] = str(nb + 1)\n",
        "\n",
        "    # Make different nodes for words and non-words\n",
        "    word = ''\n",
        "    for char in line.strip():\n",
        "        if char.isalpha():\n",
        "            word += char\n",
        "        else:\n",
        "            word_node = lxml.etree.Element('w')\n",
        "            word_node.text = word\n",
        "            line_node.append(word_node)\n",
        "            word = ''\n",
        "\n",
        "            char_node = lxml.etree.Element('c')\n",
        "            char_node.text = char\n",
        "            line_node.append(char_node)\n",
        "\n",
        "    # don't forget last word:\n",
        "    if word:\n",
        "        word_node = lxml.etree.Element('w')\n",
        "        word_node.text = word\n",
        "        line_node.append(word_node)\n",
        "\n",
        "    rhyme_node = lxml.etree.Element('rhyme')\n",
        "    # We use xpath to find the final w-element in the line\n",
        "    # and wrap it in a line element\n",
        "    rhyme_node.append(line_node.xpath('//w')[-1])\n",
        "    line_node.replace(line_node.xpath('//w')[-1], rhyme_node)\n",
        "\n",
        "    root.append(line_node)\n",
        "\n",
        "    # Add the volta node\n",
        "    if nb == 8:\n",
        "        node = lxml.etree.Element('volta')\n",
        "        root.append(node)\n",
        "\n",
        "tree = lxml.etree.ElementTree(root)\n",
        "xml_string = lxml.etree.tostring(tree, pretty_print=True).decode()\n",
        "# Print a snippet of the tree:\n",
        "print(xml_string[:xml_string.find(\"</line>\") + 8] + '  ...')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "819f8d7d-19fe-497d-a38b-eca99257f6f5",
      "metadata": {
        "id": "819f8d7d-19fe-497d-a38b-eca99257f6f5"
      },
      "outputs": [],
      "source": [
        "tree = lxml.etree.parse(folderpath+'data/folger/xml/Oth.xml')\n",
        "print(tree.getroot().find('.//{http://www.tei-c.org/ns/1.0}title').text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "449c69e8-6052-4fff-bf5c-666a833dc455",
      "metadata": {
        "id": "449c69e8-6052-4fff-bf5c-666a833dc455"
      },
      "outputs": [],
      "source": [
        "print(tree.getroot().find('title'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b80baa68-98de-408a-afe0-90a1bdab2e44",
      "metadata": {
        "id": "b80baa68-98de-408a-afe0-90a1bdab2e44"
      },
      "outputs": [],
      "source": [
        "NSMAP = {'tei': 'http://www.tei-c.org/ns/1.0'}\n",
        "print(tree.getroot().find('.//tei:title', namespaces=NSMAP).text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bdf8718-72b1-4cbf-859e-c85d1428364f",
      "metadata": {
        "id": "1bdf8718-72b1-4cbf-859e-c85d1428364f"
      },
      "outputs": [],
      "source": [
        "import bs4 as bs\n",
        "\n",
        "html_doc = \"\"\"\n",
        "<html>\n",
        "  <head>\n",
        "    <title>Henry IV, Part I</title>\n",
        "  </head>\n",
        "  <body>\n",
        "    <div>\n",
        "      <p class=\"speaker\">KING</p>\n",
        "      <p id=\"line-1.1.1\">\n",
        "        <a id=\"ftln-0001\">FTLN 0001</a>\n",
        "        So shaken as we are, so wan with care,\n",
        "      </p>\n",
        "      <p id=\"line-1.1.2\">\n",
        "        <a id=\"ftln-0002\">FTLN 0002</a>\n",
        "        Find we a time for frighted peace to pant\n",
        "      </p>\n",
        "      <p id=\"line-1.1.3\">\n",
        "        <a id=\"ftln-0003\">FTLN 0003</a>\n",
        "        And breathe short-winded accents of new broils\n",
        "      </p>\n",
        "      <p id=\"line-1.1.4\">\n",
        "        <a id=\"ftln-0004\">FTLN 0004</a>\n",
        "        To be commenced in strands afar remote.\n",
        "      </p>\n",
        "    </div>\n",
        "  </body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "html = bs.BeautifulSoup(html_doc, 'html.parser')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5882b59-25c0-4daa-87dc-8e9e73ebc62d",
      "metadata": {
        "id": "e5882b59-25c0-4daa-87dc-8e9e73ebc62d"
      },
      "outputs": [],
      "source": [
        "# print the documents <title> (from head)\n",
        "print(html.title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a9a5e61-7751-4aff-b640-45ef9062e02f",
      "metadata": {
        "id": "8a9a5e61-7751-4aff-b640-45ef9062e02f"
      },
      "outputs": [],
      "source": [
        "# print the first <p> element and its content\n",
        "print(html.p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c932f13-465b-4bef-9d1f-5e3407ab2b5f",
      "metadata": {
        "id": "6c932f13-465b-4bef-9d1f-5e3407ab2b5f"
      },
      "outputs": [],
      "source": [
        "# print the text of a particular element, e.g. the <title>\n",
        "print(html.title.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "916d493b-4bec-4b6a-a1ea-3c0b625547d9",
      "metadata": {
        "id": "916d493b-4bec-4b6a-a1ea-3c0b625547d9"
      },
      "outputs": [],
      "source": [
        "# print the parent tag (and its content) of the first <p> element\n",
        "print(html.p.parent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fe922bd-c4fd-4069-8444-02259d65640b",
      "metadata": {
        "id": "2fe922bd-c4fd-4069-8444-02259d65640b"
      },
      "outputs": [],
      "source": [
        "# print the parent tag name of the first <p> element\n",
        "print(html.p.parent.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "481413ee-b1bc-4450-89a1-d0417afdef32",
      "metadata": {
        "id": "481413ee-b1bc-4450-89a1-d0417afdef32"
      },
      "outputs": [],
      "source": [
        "# find all occurrences of the <a> element\n",
        "print(html.find_all('a'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9f2e955-4f70-4176-9413-586029cd72c4",
      "metadata": {
        "id": "e9f2e955-4f70-4176-9413-586029cd72c4"
      },
      "outputs": [],
      "source": [
        "# find a <p> element with a specific ID\n",
        "print(html.find('p', id='line-1.1.3'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1aab736c-8fc8-4ea8-bd0b-ddb4ee909f56",
      "metadata": {
        "id": "1aab736c-8fc8-4ea8-bd0b-ddb4ee909f56"
      },
      "outputs": [],
      "source": [
        "def html2txt(fpath):\n",
        "    \"\"\"Convert text from a HTML file into a string.\n",
        "\n",
        "    Arguments:\n",
        "        fpath: a string pointing to the filename of the HTML file\n",
        "\n",
        "    Returns:\n",
        "        A string representing the text extracted from the supplied\n",
        "        HTML file.\n",
        "\n",
        "    \"\"\"\n",
        "    with open(fpath) as f:\n",
        "        html = bs.BeautifulSoup(f, 'html.parser')\n",
        "    return html.get_text()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7a8a4b2-462f-4a04-a4a4-7ca7e4fc5c2c",
      "metadata": {
        "id": "a7a8a4b2-462f-4a04-a4a4-7ca7e4fc5c2c"
      },
      "outputs": [],
      "source": [
        "fp = folderpath+'data/folger/html/1H4.html'\n",
        "text = html2txt(fp)\n",
        "start = text.find('Henry V')\n",
        "print(text[start:start + 500])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21e1b6c1-1941-4397-a25c-264a2abf522f",
      "metadata": {
        "id": "21e1b6c1-1941-4397-a25c-264a2abf522f"
      },
      "outputs": [],
      "source": [
        "with open(fp) as f:\n",
        "    html = bs.BeautifulSoup(f, 'html.parser')\n",
        "toc = html.find('table', attrs={'class': 'contents'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "221290de-ed33-4403-9b6e-74fa8a6522ad",
      "metadata": {
        "id": "221290de-ed33-4403-9b6e-74fa8a6522ad"
      },
      "outputs": [],
      "source": [
        "def toc_hrefs(html):\n",
        "    \"\"\"Return a list of hrefs from a document's table of contents.\"\"\"\n",
        "    toc = html.find('table', attrs={'class': 'contents'})\n",
        "    hrefs = []\n",
        "    for tr in toc.find_all('tr'):\n",
        "        for td in tr.find_all('td'):\n",
        "            for a in td.find_all('a'):\n",
        "                hrefs.append(a.get('href'))\n",
        "    return hrefs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca9ef045-3702-4e49-be56-ee2d197e42fa",
      "metadata": {
        "id": "ca9ef045-3702-4e49-be56-ee2d197e42fa"
      },
      "outputs": [],
      "source": [
        "items = toc_hrefs(html)\n",
        "print(items[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21642dc7-4126-4ad6-8e09-1501cd579435",
      "metadata": {
        "id": "21642dc7-4126-4ad6-8e09-1501cd579435"
      },
      "outputs": [],
      "source": [
        "def get_href_div(html, href):\n",
        "    \"\"\"Retrieve the <div> element corresponding to the given href.\"\"\"\n",
        "    href = href.lstrip('#')\n",
        "    div = html.find('div', attrs={'id': href})\n",
        "    if div is None:\n",
        "        div = html.find('a', attrs={'name': href}).findNext('div')\n",
        "    return div"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "019ec370-aec8-4c74-8ea9-1611e486da6e",
      "metadata": {
        "id": "019ec370-aec8-4c74-8ea9-1611e486da6e"
      },
      "outputs": [],
      "source": [
        "def html2txt(fname, concatenate=False):\n",
        "    \"\"\"Convert text from a HTML file into a string or sequence of strings.\n",
        "\n",
        "    Arguments:\n",
        "        fpath: a string pointing to the filename of the HTML file.\n",
        "        concatenate: a boolean indicating whether to concatenate the\n",
        "            extracted texts into a single string. If False, a list of\n",
        "            strings representing the individual sections is returned.\n",
        "\n",
        "    Returns:\n",
        "        A string or list of strings representing the text extracted\n",
        "        from the supplied HTML file.\n",
        "\n",
        "    \"\"\"\n",
        "    with open(fname) as f:\n",
        "        html = bs.BeautifulSoup(f, 'html.parser')\n",
        "    # Use a concise list comprehension to create the list of texts.\n",
        "    # The same list could be constructed using an ordinary for-loop:\n",
        "    #    texts = []\n",
        "    #    for href in toc_hrefs(html):\n",
        "    #        text = get_href_div(html, href).get_text()\n",
        "    #        texts.append(text)\n",
        "    texts = [get_href_div(html, href).get_text() for href in toc_hrefs(html)]\n",
        "    return '\\n'.join(texts) if concatenate else texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f472d9dc-403a-4001-8d2e-ae146e867ef1",
      "metadata": {
        "id": "f472d9dc-403a-4001-8d2e-ae146e867ef1"
      },
      "outputs": [],
      "source": [
        "texts = html2txt(fp)\n",
        "print(texts[6][:200])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fac531b-5d9a-4f9c-bab6-b6a871621868",
      "metadata": {
        "id": "5fac531b-5d9a-4f9c-bab6-b6a871621868"
      },
      "outputs": [],
      "source": [
        "import urllib.request"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81e7be49-b00e-4998-8bfb-74ba24fc5656",
      "metadata": {
        "id": "81e7be49-b00e-4998-8bfb-74ba24fc5656"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "\n",
        "url = 'https://en.wikipedia.org/wiki/William_Shakespeare'\n",
        "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
        "req = urllib.request.Request(url, headers=headers)\n",
        "page = urllib.request.urlopen(req)\n",
        "html = page.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58af682e-b7e8-4a4f-8617-dbb9f61b22ef",
      "metadata": {
        "id": "58af682e-b7e8-4a4f-8617-dbb9f61b22ef"
      },
      "outputs": [],
      "source": [
        "import bs4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d560fa3-0165-4e08-b2ff-3f8800ff1b90",
      "metadata": {
        "id": "9d560fa3-0165-4e08-b2ff-3f8800ff1b90"
      },
      "outputs": [],
      "source": [
        "soup = bs4.BeautifulSoup(html, 'html.parser')\n",
        "print(soup.get_text().strip()[:300])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24334447-74bb-4f44-a6f7-ec5584065e34",
      "metadata": {
        "id": "24334447-74bb-4f44-a6f7-ec5584065e34"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dcc41e9-fb85-4bc1-a861-fae3ee83729f",
      "metadata": {
        "id": "6dcc41e9-fb85-4bc1-a861-fae3ee83729f"
      },
      "outputs": [],
      "source": [
        "for script in soup(['script', 'style']):\n",
        "    script.extract()\n",
        "text = soup.get_text()\n",
        "text = re.sub('\\s*\\n+\\s*', '\\n', text)  # remove multiple linebreaks:\n",
        "print(text[:300])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13c2706e-e4b6-4735-9a73-97b55cfa3258",
      "metadata": {
        "id": "13c2706e-e4b6-4735-9a73-97b55cfa3258"
      },
      "outputs": [],
      "source": [
        "links = soup.find_all('a')\n",
        "print(links[9].prettify())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d39aff8c-67c7-4223-a2ed-b1eaf38fcf23",
      "metadata": {
        "id": "d39aff8c-67c7-4223-a2ed-b1eaf38fcf23"
      },
      "outputs": [],
      "source": [
        "V = {1, 2, 3, 4, 5}\n",
        "E = {(1, 2), (1, 4), (2, 5), (3, 4), (4, 5)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78b07a1d-a4ee-48b6-a812-f989830b7778",
      "metadata": {
        "id": "78b07a1d-a4ee-48b6-a812-f989830b7778"
      },
      "outputs": [],
      "source": [
        "import networkx as nx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c203f515-cfa4-4a6a-b94e-22326e50b395",
      "metadata": {
        "id": "c203f515-cfa4-4a6a-b94e-22326e50b395"
      },
      "outputs": [],
      "source": [
        "G = nx.Graph()\n",
        "G.add_nodes_from(V)\n",
        "G.add_edges_from(E)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8149e389-71cf-4050-b928-234e5ac4741b",
      "metadata": {
        "id": "8149e389-71cf-4050-b928-234e5ac4741b"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2a90b49-1006-43cc-bc40-4bf9595070a7",
      "metadata": {
        "id": "a2a90b49-1006-43cc-bc40-4bf9595070a7"
      },
      "outputs": [],
      "source": [
        "nx.draw_networkx(G, font_color=\"white\")\n",
        "plt.axis('off');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37b1d695-3f53-4df5-9e0a-860a1ad8c0ea",
      "metadata": {
        "id": "37b1d695-3f53-4df5-9e0a-860a1ad8c0ea"
      },
      "outputs": [],
      "source": [
        "NSMAP = {'tei': 'http://www.tei-c.org/ns/1.0'}\n",
        "\n",
        "\n",
        "def character_network(tree):\n",
        "    \"\"\"Construct a character interaction network.\n",
        "\n",
        "    Construct a character interaction network for Shakespeare texts in\n",
        "    the Folger Digital Text collection. Character interaction networks\n",
        "    are constructed on the basis of successive speaker turns in the texts,\n",
        "    and edges between speakers are created when their utterances follow\n",
        "    one another.\n",
        "\n",
        "    Arguments:\n",
        "        tree: An lxml.ElementTree instance representing one of the XML\n",
        "            files in the Folger Shakespeare collection.\n",
        "\n",
        "    Returns:\n",
        "        A character interaction network represented as a weighted,\n",
        "        undirected NetworkX Graph.\n",
        "\n",
        "    \"\"\"\n",
        "    G = nx.Graph()\n",
        "    # extract a list of speaker turns for each scene in a play\n",
        "    for scene in tree.iterfind('.//tei:div2[@type=\"scene\"]', NSMAP):\n",
        "        speakers = scene.findall('.//tei:sp', NSMAP)\n",
        "        # iterate over the sequence of speaker turns...\n",
        "        for i in range(len(speakers) - 1):\n",
        "            # ... and extract pairs of adjacent speakers\n",
        "            try:\n",
        "                speaker_i = speakers[i].attrib['who'].split('_')[0].replace('#', '')\n",
        "                speaker_j = speakers[i + 1].attrib['who'].split('_')[0].replace('#', '')\n",
        "                # if the interaction between two speakers has already\n",
        "                # been attested, update their interaction count\n",
        "                if G.has_edge(speaker_i, speaker_j):\n",
        "                    G[speaker_i][speaker_j]['weight'] += 1\n",
        "                # else add an edge between speaker i and j to the graph\n",
        "                else:\n",
        "                    G.add_edge(speaker_i, speaker_j, weight=1)\n",
        "            except KeyError:\n",
        "                continue\n",
        "    return G"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26fa01f6-f684-49ab-af7f-3ae2fb2b4432",
      "metadata": {
        "id": "26fa01f6-f684-49ab-af7f-3ae2fb2b4432"
      },
      "outputs": [],
      "source": [
        "tree = lxml.etree.parse(folderpath+'data/folger/xml/Ham.xml')\n",
        "G = character_network(tree.getroot())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14895ef5-6826-4aa2-b3e2-031f3f02683e",
      "metadata": {
        "id": "14895ef5-6826-4aa2-b3e2-031f3f02683e"
      },
      "outputs": [],
      "source": [
        "print(f\"N nodes = {G.number_of_nodes()}, N edges = {G.number_of_edges()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b45478a0-4b3a-4b28-b8bd-b4f9e95c3715",
      "metadata": {
        "id": "b45478a0-4b3a-4b28-b8bd-b4f9e95c3715"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "\n",
        "interactions = collections.Counter()\n",
        "\n",
        "for speaker_i, speaker_j, data in G.edges(data=True):\n",
        "    interaction_count = data['weight']\n",
        "    interactions[speaker_i] += interaction_count\n",
        "    interactions[speaker_j] += interaction_count\n",
        "\n",
        "nodesizes = [interactions[speaker] * 5 for speaker in G]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df3797da-4567-417d-9b16-c33bf2616026",
      "metadata": {
        "id": "df3797da-4567-417d-9b16-c33bf2616026"
      },
      "outputs": [],
      "source": [
        "# Create an empty figure of size 15x15\n",
        "fig = plt.figure(figsize=(15, 15))\n",
        "# Compute the positions of the nodes using the spring layout algorithm\n",
        "pos = nx.spring_layout(G, k=0.5, iterations=200)\n",
        "# Then, add the edges to the visualization\n",
        "nx.draw_networkx_edges(G, pos, alpha=0.4)\n",
        "# Subsequently, add the weighted nodes to the visualization\n",
        "nx.draw_networkx_nodes(G, pos, node_size=nodesizes, alpha=0.4)\n",
        "# Finally, add the labels (i.e. the speaker IDs) to the visualization\n",
        "nx.draw_networkx_labels(G, pos)\n",
        "plt.axis('off');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3525948-6a65-4a7a-92e8-164f318a1068",
      "metadata": {
        "id": "c3525948-6a65-4a7a-92e8-164f318a1068"
      },
      "outputs": [],
      "source": [
        "from copy import deepcopy\n",
        "G0 = deepcopy(G)\n",
        "\n",
        "for u, v, d in G0.edges(data=True):\n",
        "    d['weight'] = 1\n",
        "\n",
        "nodesizes = [interactions[speaker] * 5 for speaker in G0]\n",
        "\n",
        "fig = plt.figure(figsize=(15, 15))\n",
        "pos = nx.spring_layout(G0, k=0.5, iterations=200)\n",
        "nx.draw_networkx_edges(G0, pos, alpha=0.4)\n",
        "nx.draw_networkx_nodes(G0, pos, node_size=nodesizes, alpha=0.4)\n",
        "nx.draw_networkx_labels(G0, pos)\n",
        "plt.axis('off');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6129196-05a5-4e85-b60e-ebbd3183565a",
      "metadata": {
        "id": "e6129196-05a5-4e85-b60e-ebbd3183565a"
      },
      "outputs": [],
      "source": [
        "G0.remove_node('Hamlet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82fc013b-f8e2-433b-b775-9e803590016b",
      "metadata": {
        "id": "82fc013b-f8e2-433b-b775-9e803590016b"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(15, 15))\n",
        "pos = nx.spring_layout(G0, k=0.5, iterations=200)\n",
        "nodesizes = [interactions[speaker] * 5 for speaker in G0]\n",
        "nx.draw_networkx_edges(G0, pos, alpha=0.4)\n",
        "nx.draw_networkx_nodes(G0, pos, node_size=nodesizes, alpha=0.4)\n",
        "nx.draw_networkx_labels(G0, pos)\n",
        "plt.axis('off');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ecac1af-be49-428e-9aa6-c03d605e15b8",
      "metadata": {
        "id": "2ecac1af-be49-428e-9aa6-c03d605e15b8"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from networkx.readwrite import json_graph\n",
        "\n",
        "with open('hamlet.json', 'w') as f:\n",
        "    json.dump(json_graph.node_link_data(G), f)\n",
        "\n",
        "with open('hamlet.json') as f:\n",
        "    d = json.load(f)\n",
        "\n",
        "G = json_graph.node_link_graph(d)\n",
        "print(f\"Graph with {len(G.nodes())} nodes and {len(G.edges())} edges.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e4d96d9-c1c7-4d1f-9013-f32b1f6f0173",
      "metadata": {
        "id": "7e4d96d9-c1c7-4d1f-9013-f32b1f6f0173"
      },
      "outputs": [],
      "source": [
        "# Undocumented code snippet used in chapter (e.g., for figure generation)\n",
        "import functools\n",
        "from copy import deepcopy\n",
        "G1 = deepcopy(G)\n",
        "\n",
        "for u, v, d in G.edges(data=True):\n",
        "    if d[\"weight\"] < 10:\n",
        "        G1.remove_edge(u, v)\n",
        "\n",
        "G1 = nx.relabel_nodes(G1, {\"SOLDIERS.FORTINBRAS.Captain\": \"Fortinbras.Captain\"})\n",
        "# rename verbose name for Fortinbras' Captain\n",
        "#SOLDIERS.FORTINBRAS.Captain\n",
        "\n",
        "subgraphs = [G1.subgraph(c).copy() for c in nx.connected_components(G1)]\n",
        "# functools.reduce is similar to foldl in Haskell and fold_left in OCaml\n",
        "def larger_graph(graph1, graph2):\n",
        "    return graph2 if len(graph2.nodes()) > len(graph1.nodes()) else graph1\n",
        "G1 = functools.reduce(larger_graph, subgraphs, subgraphs[0])\n",
        "\n",
        "fig = plt.figure(figsize=(9, 6))\n",
        "pos = nx.spring_layout(G1, k=0.5, iterations=2000, seed=1)\n",
        "nx.draw_networkx_edges(G1, pos, alpha=0.4)\n",
        "nx.draw_networkx_nodes(G1, pos, node_size=[degree * 100 for _, degree in G1.degree()], alpha=0.4)\n",
        "nx.draw_networkx_labels(G1, pos)\n",
        "plt.axis('off')\n",
        "plt.tight_layout()\n",
        "#plt.savefig(folderpath+'img/hamlet-minimum-10-interactions.png')\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}