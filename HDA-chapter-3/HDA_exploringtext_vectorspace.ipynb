{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "328c0637-35c1-432e-b8de-d3759962771b",
   "metadata": {},
   "source": [
    "# Humanities Data Analysis: Case studies with Python\n",
    "--------------------------------------------------\n",
    "Folgert Karsdorp, Mike Kestemont & Allen Riddell\n",
    "Chapter 3: Exploring Texts using the Vector Space Model\n",
    "\n",
    "https://www.humanitiesdataanalysis.org/vector-space-model/notebook.html#from-texts-to-vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62ba3e9-2c90-410b-8c43-45751158218b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/jazoza/cultural-data-analysis.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af82f3eb-1412-42db-ac5e-a40886f5b1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "folderpath='cultural-data-analysis/HDA-chapter-3/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be6abf3-2b83-46e7-a8ba-756bbca48cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undocumented code snippet used in chapter (e.g., for figure generation)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "document_term_matrix = np.array([[1, 16], [2, 18], [35, 0], [39, 1]])\n",
    "labels = '$d_1$', '$d_2$', '$d_3$', '$d_4$'\n",
    "plt.quiver([0, 0, 0, 0], [0, 0, 0, 0],\n",
    "           document_term_matrix[:, 0], document_term_matrix[:, 1],\n",
    "           color=[\"C0\", \"C1\", \"C2\", \"C3\"], angles='xy', scale_units='xy', scale=1)\n",
    "for i, label in enumerate(labels):\n",
    "    plt.annotate(label, xy=document_term_matrix[i], fontsize=15)\n",
    "plt.ylim(-1, 20); plt.xlim(-1, 44)\n",
    "plt.xlabel(\"Dimension 1\")\n",
    "plt.ylabel(\"Dimension 3\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db74e2b4-7939-4b30-bf7c-5f443a0bd701",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\"D'où me vient ce désordre, Aufide, et que veut dire\",\n",
    "          \"Madame, il était temps qu'il vous vînt du secours:\",\n",
    "          \"Ah! Monsieur, c'est donc vous?\",\n",
    "          \"Ami, j'ai beau rêver, toute ma rêverie\",\n",
    "          \"Ne me parle plus tant de joie et d'hyménée;\",\n",
    "          \"Il est vrai, Cléobule, et je veux l'avouer,\",\n",
    "          \"Laisse-moi mon chagrin, tout injuste qu'il est;\",\n",
    "          \"Ton frère, je l'avoue, a beaucoup de mérite;\",\n",
    "          \"J'en demeure d'accord, chacun a sa méthode;\",\n",
    "          'Pour prix de votre amour que vous peignez extrême,']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebe6d9f-890d-4ec7-bc58-70397bdc55cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = corpus[2]\n",
    "print(document.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a41187d-1350-44cf-93f1-7e619c464beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import nltk.tokenize\n",
    "\n",
    "# download the most recent punkt package\n",
    "nltk.download('punkt', quiet=True)\n",
    "\n",
    "document = corpus[3]\n",
    "print(nltk.tokenize.word_tokenize(document, language='french'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8572306e-40bd-499f-aca5-a255f3b9de53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "PUNCT_RE = re.compile(r'[^\\w\\s]+$')\n",
    "\n",
    "\n",
    "def is_punct(string):\n",
    "    \"\"\"Check if STRING is a punctuation marker or a sequence of\n",
    "       punctuation markers.\n",
    "\n",
    "    Arguments:\n",
    "        string (str): a string to check for punctuation markers.\n",
    "\n",
    "    Returns:\n",
    "        bool: True is string is a (sequence of) punctuation marker(s),\n",
    "            False otherwise.\n",
    "\n",
    "    Examples:\n",
    "        >>> is_punct(\"!\")\n",
    "        True\n",
    "        >>> is_punct(\"Bonjour!\")\n",
    "        False\n",
    "        >>> is_punct(\"¿Te gusta el verano?\")\n",
    "        False\n",
    "        >>> is_punct(\"...\")\n",
    "        True\n",
    "        >>> is_punct(\"«»...\")\n",
    "        True\n",
    "\n",
    "    \"\"\"\n",
    "    return PUNCT_RE.match(string) is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f59cf7c-337e-4b4e-bad2-9d5ba36d016d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.tokenize.word_tokenize(corpus[2], language='french')\n",
    "\n",
    "# Loop with a standard for-loop\n",
    "tokenized = []\n",
    "for token in tokens:\n",
    "    if not is_punct(token):\n",
    "        tokenized.append(token)\n",
    "print(tokenized)\n",
    "\n",
    "# Loop with a list comprehension\n",
    "tokenized = [token for token in tokens if not is_punct(token)]\n",
    "print(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4501280-598e-491d-8223-27d704cc9bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, language, lowercase=True):\n",
    "    \"\"\"Preprocess a text.\n",
    "\n",
    "    Perform a text preprocessing procedure, which transforms a string\n",
    "    object into a list of word tokens without punctuation markers.\n",
    "\n",
    "    Arguments:\n",
    "        text (str): a string representing a text.\n",
    "        language (str): a string specifying the language of text.\n",
    "        lowercase (bool, optional): Set to True to lowercase all\n",
    "            word tokens. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        list: a list of word tokens extracted from text, excluding\n",
    "            punctuation.\n",
    "\n",
    "    Examples:\n",
    "        >>> preprocess_text(\"Ah! Monsieur, c'est donc vous?\", 'french')\n",
    "        [\"ah\", \"monsieur\", \"c'est\", \"donc\", \"vous\"]\n",
    "\n",
    "    \"\"\"\n",
    "    if lowercase:\n",
    "        text = text.lower()\n",
    "    tokens = nltk.tokenize.word_tokenize(text, language=language)\n",
    "    tokens = [token for token in tokens if not is_punct(token)]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e46b7c-ebef-4d1e-89ab-6d44b5fe6d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "for document in corpus[2:4]:\n",
    "    print('Original:', document)\n",
    "    print('Tokenized:', preprocess_text(document, 'french'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f89e8c-5b92-42a6-8ff6-fcdd569ac721",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "vocabulary = collections.Counter()\n",
    "for document in corpus:\n",
    "    vocabulary.update(preprocess_text(document, 'french'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ae3b0b-f45e-4ec9-84a1-086461c21f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vocabulary.most_common(n=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8f0709-c07d-4c5b-bdbc-3aa33bf77bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original vocabulary size:', len(vocabulary))\n",
    "pruned_vocabulary = {token for token, count in vocabulary.items() if count > 1}\n",
    "print(pruned_vocabulary)\n",
    "print('Pruned vocabulary size:', len(pruned_vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f640dd8-8a43-4a99-9999-b7a2c4c55d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "print('Original vocabulary size:', len(vocabulary))\n",
    "pruned_vocabulary = {token for token, _ in vocabulary.most_common()[n:]}\n",
    "print('Pruned vocabulary size:', len(pruned_vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a7c69f-548c-4d27-9a92-d02940737363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_vocabulary(tokenized_corpus, min_count=1, max_count=float('inf')):\n",
    "    \"\"\"Extract a vocabulary from a tokenized corpus.\n",
    "\n",
    "    Arguments:\n",
    "        tokenized_corpus (list): a tokenized corpus represented, list\n",
    "            of lists of strings.\n",
    "        min_count (int, optional): the minimum occurrence count of a\n",
    "            vocabulary item in the corpus.\n",
    "        max_count (int, optional): the maximum occurrence count of a\n",
    "            vocabulary item in the corpus. Defaults to inf.\n",
    "\n",
    "    Returns:\n",
    "        list: An alphabetically ordered list of unique words in the\n",
    "            corpus, of which the frequencies adhere to the specified\n",
    "            minimum and maximum count.\n",
    "\n",
    "    Examples:\n",
    "        >>> corpus = [['the', 'man', 'love', 'man', 'the'],\n",
    "                      ['the', 'love', 'book', 'wise', 'drama'],\n",
    "                      ['a', 'story', 'book', 'drama']]\n",
    "        >>> extract_vocabulary(corpus, min_count=2)\n",
    "        ['book', 'drama', 'love', 'man', 'the']\n",
    "\n",
    "    \"\"\"\n",
    "    vocabulary = collections.Counter()\n",
    "    for document in tokenized_corpus:\n",
    "        vocabulary.update(document)\n",
    "    vocabulary = {word for word, count in vocabulary.items()\n",
    "                  if count >= min_count and count <= max_count}\n",
    "    return sorted(vocabulary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae237cb9-361a-4ab9-b057-1fc2401ebbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_corpus = [preprocess_text(document, 'french') for document in corpus]\n",
    "vocabulary = extract_vocabulary(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cb946e-e9fc-4097-8e2a-d9c382db8d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "bags_of_words = []\n",
    "for document in tokenized_corpus:\n",
    "    tokens = [word for word in document if word in vocabulary]\n",
    "    bags_of_words.append(collections.Counter(tokens))\n",
    "\n",
    "print(bags_of_words[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6182b6-91f9-4da0-a9d6-27f9ad187264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus2dtm(tokenized_corpus, vocabulary):\n",
    "    \"\"\"Transform a tokenized corpus into a document-term matrix.\n",
    "\n",
    "    Arguments:\n",
    "        tokenized_corpus (list): a tokenized corpus as a list of\n",
    "        lists of strings. vocabulary (list): An list of unique words.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of lists representing the frequency of each term\n",
    "              in `vocabulary` for each document in the corpus.\n",
    "\n",
    "    Examples:\n",
    "        >>> tokenized_corpus = [['the', 'man', 'man', 'smart'],\n",
    "                                ['a', 'the', 'man' 'love'],\n",
    "                                ['love', 'book', 'journey']]\n",
    "        >>> vocab = ['book', 'journey', 'man', 'love']\n",
    "        >>> corpus2dtm(tokenized_corpus, vocabulary)\n",
    "        [[0, 0, 2, 0], [0, 0, 1, 1], [1, 1, 0, 1]]\n",
    "\n",
    "    \"\"\"\n",
    "    document_term_matrix = []\n",
    "    for document in tokenized_corpus:\n",
    "        document_counts = collections.Counter(document)\n",
    "        row = [document_counts[word] for word in vocabulary]\n",
    "        document_term_matrix.append(row)\n",
    "    return document_term_matrix\n",
    "\n",
    "\n",
    "document_term_matrix = corpus2dtm(tokenized_corpus, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217f7ef2-5662-4f2d-88d2-f2b6c084a7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undocumented code snippet used in chapter (e.g., for figure generation)\n",
    "import pandas as pd\n",
    "pd.DataFrame(document_term_matrix, columns=vocabulary).iloc[0:5, 0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0769fcaa-9a1b-4b04-9aad-322370f3bc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "document_term_matrix = np.array(document_term_matrix)\n",
    "print(document_term_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d1cf2b-1c1b-45c9-aab4-285518e01111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import lxml.etree\n",
    "import tarfile\n",
    "\n",
    "tf = tarfile.open('data/theatre-classique.tar.gz', 'r')\n",
    "tf.extractall('data')\n",
    "\n",
    "subgenres = ('Comédie', 'Tragédie', 'Tragi-comédie')\n",
    "\n",
    "plays, titles, genres = [], [], []\n",
    "for fn in os.scandir('data/theatre-classique'):\n",
    "    # Only include XML files\n",
    "    if not fn.name.endswith('.xml'):\n",
    "        continue\n",
    "    tree = lxml.etree.parse(fn.path)\n",
    "    genre = tree.find('//genre')\n",
    "    title = tree.find('//title')\n",
    "    if genre is not None and genre.text in subgenres:\n",
    "        lines = []\n",
    "        for line in tree.xpath('//l|//p'):\n",
    "            lines.append(' '.join(line.itertext()))\n",
    "        text = '\\n'.join(lines)\n",
    "        plays.append(text)\n",
    "        genres.append(genre.text)\n",
    "        titles.append(title.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf99cbc-1e1f-4155-be4d-16241e71755f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "counts = collections.Counter(genres)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(counts.keys(), counts.values(), width=0.3)\n",
    "ax.set(xlabel=\"genre\", ylabel=\"count\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f915e15-5065-48da-81e0-1b69b1756e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plays_tok = [preprocess_text(play, 'french') for play in plays]\n",
    "vocabulary = extract_vocabulary(plays_tok, min_count=2)\n",
    "document_term_matrix = np.array(corpus2dtm(plays_tok, vocabulary))\n",
    "\n",
    "print(f\"document-term matrix with \"\n",
    "      f\"|D| = {document_term_matrix.shape[0]} documents and \"\n",
    "      f\"|V| = {document_term_matrix.shape[1]} words.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedb7bd4-1553-437a-9078-33708cadab9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "monsieur_idx = vocabulary.index('monsieur')\n",
    "sang_idx = vocabulary.index('sang')\n",
    "\n",
    "monsieur_counts = document_term_matrix[:, monsieur_idx]\n",
    "sang_counts = document_term_matrix[:, sang_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff1d343-a502-4e8c-98e9-f37353b83782",
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = np.array(genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566b867e-dc94-48c5-9e9a-ab89944a3b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "for genre in ('Comédie', 'Tragédie', 'Tragi-comédie'):\n",
    "    ax.scatter(monsieur_counts[genres == genre],\n",
    "               sang_counts[genres == genre],\n",
    "               label=genre, alpha=0.7)\n",
    "\n",
    "ax.set(xlabel='monsieur', ylabel='sang')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c258d1d-ec4d-4108-b49a-4674166c584c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_means = document_term_matrix[genres == 'Tragédie'].mean(axis=0)\n",
    "co_means = document_term_matrix[genres == 'Comédie'].mean(axis=0)\n",
    "tc_means = document_term_matrix[genres == 'Tragi-comédie'].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3536f5ed-eb01-4a54-afe9-e62d382f906c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tr_means.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee43907-454a-4fae-92fe-be4d2b1403cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean absolute frequency of \"monsieur\"')\n",
    "print(f'   in comédies: {co_means[monsieur_idx]:.2f}')\n",
    "print(f'   in tragédies: {tr_means[monsieur_idx]:.2f}')\n",
    "print(f'   in tragi-comédies: {tc_means[monsieur_idx]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c66cfa-8244-488f-86f7-eb7731a430c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(\n",
    "    co_means[monsieur_idx], co_means[sang_idx], label='Comédies')\n",
    "ax.scatter(\n",
    "    tr_means[monsieur_idx], tr_means[sang_idx], label='Tragédie')\n",
    "ax.scatter(\n",
    "    tc_means[monsieur_idx], tc_means[sang_idx], label='Tragi-comédies')\n",
    "\n",
    "ax.set(xlabel='monsieur', ylabel='sang')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6204434b-01eb-4241-8cc9-c8a924a3f1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tragedy = np.array([tr_means[monsieur_idx], tr_means[sang_idx]])\n",
    "comedy = np.array([co_means[monsieur_idx], co_means[sang_idx]])\n",
    "tragedy_comedy = np.array([tc_means[monsieur_idx], tc_means[sang_idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99828a2-fe4f-4a21-8619-41cdf7e0b5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undocumented code snippet used in chapter (e.g., for figure generation)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot([tr_means[monsieur_idx], tc_means[monsieur_idx]],\n",
    "        [tr_means[sang_idx], tc_means[sang_idx]],\n",
    "        'darkgrey', lw=2, ls='--')\n",
    "ax.plot([tr_means[monsieur_idx], co_means[monsieur_idx]],\n",
    "        [tr_means[sang_idx], co_means[sang_idx]],\n",
    "        'darkgrey', lw=2, ls='--')\n",
    "ax.plot([tc_means[monsieur_idx], co_means[monsieur_idx]],\n",
    "        [tc_means[sang_idx], co_means[sang_idx]],\n",
    "        'darkgrey', lw=2, ls='--')\n",
    "\n",
    "ax.scatter(co_means[monsieur_idx], co_means[sang_idx],\n",
    "           label='Comédies', zorder=3)\n",
    "ax.scatter(tr_means[monsieur_idx], tr_means[sang_idx],\n",
    "           label='Tragédie', zorder=3)\n",
    "ax.scatter(tc_means[monsieur_idx], tc_means[sang_idx],\n",
    "           label='Tragi-comédies', zorder=3)\n",
    "\n",
    "ax.set(xlabel='monsieur', ylabel='sang')\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, 1.1), ncol=3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31483ab2-ca81-4c7e-b350-ea0e74a2a1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(a, b):\n",
    "    \"\"\"Compute the Euclidean distance between two vectors.\n",
    "\n",
    "    Note: ``numpy.linalg.norm(a - b)`` performs the\n",
    "    same calculation using a slightly faster method.\n",
    "\n",
    "    Arguments:\n",
    "        a (numpy.ndarray): a vector of floats or ints.\n",
    "        b (numpy.ndarray): a vector of floats or ints.\n",
    "\n",
    "    Returns:\n",
    "        float: The euclidean distance between vector a and b.\n",
    "\n",
    "    Examples:\n",
    "        >>> import numpy as np\n",
    "        >>> a = np.array([1, 4, 2, 8])\n",
    "        >>> b = np.array([2, 1, 4, 7])\n",
    "        >>> round(euclidean_distance(a, b), 2)\n",
    "        3.87\n",
    "\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.sum((a - b) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f4b01c-4e0b-4f27-b569-c317f09091f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc = euclidean_distance(tragedy, comedy)\n",
    "print(f'tragédies - comédies:       {tc:.2f}')\n",
    "\n",
    "ttc = euclidean_distance(tragedy, tragedy_comedy)\n",
    "print(f'tragédies - tragi-comédies: {ttc:.2f}')\n",
    "\n",
    "ctc = euclidean_distance(comedy, tragedy_comedy)\n",
    "print(f' comédies - tragi-comédies: {ctc:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa2dfa3-14fc-4625-ab8e-154d8c508789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undocumented code snippet used in chapter (e.g., for figure generation)\n",
    "# following two blocks with much appreciated help from:\n",
    "# https://stackoverflow.com/questions/25227100/best-way-to-plot-an-angle-between-two-lines-in-matplotlib\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Arc\n",
    "import math\n",
    "\n",
    "def get_angle_plot(line1, line2, offset = 1, color = None, origin = [0,0], len_x_axis = 1, len_y_axis = 1):\n",
    "\n",
    "    l1xy = line1.get_xydata()\n",
    "\n",
    "    # Angle between line1 and x-axis\n",
    "    slope1 = (l1xy[1][1] - l1xy[0][1]) / float(l1xy[1][0] - l1xy[0][0])\n",
    "    angle1 = abs(math.degrees(math.atan(slope1))) # Taking only the positive angle\n",
    "\n",
    "    l2xy = line2.get_xydata()\n",
    "\n",
    "    # Angle between line2 and x-axis\n",
    "    slope2 = (l2xy[1][1] - l2xy[0][1]) / float(l2xy[1][0] - l2xy[0][0])\n",
    "    angle2 = abs(math.degrees(math.atan(slope2)))\n",
    "\n",
    "    theta1 = min(angle1, angle2)\n",
    "    theta2 = max(angle1, angle2)\n",
    "\n",
    "    angle = theta2 - theta1\n",
    "\n",
    "    if color is None:\n",
    "        color = line1.get_color() # Uses the color of line 1 if color parameter is not passed.\n",
    "\n",
    "    return Arc(origin, len_x_axis*offset, len_y_axis*offset, 0, theta1, theta2, color=color)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(co_means[monsieur_idx], co_means[sang_idx],\n",
    "           label='Comédies', zorder=3)\n",
    "ax.scatter(tr_means[monsieur_idx], tr_means[sang_idx],\n",
    "           label='Tragédie', zorder=3)\n",
    "ax.scatter(tc_means[monsieur_idx], tc_means[sang_idx],\n",
    "           label='Tragic-comédies', zorder=3)\n",
    "\n",
    "# plot vectors\n",
    "line_1 = Line2D([co_means[monsieur_idx], 0], [co_means[sang_idx], 0], 2, lw=2, ls='--', c='darkgrey')\n",
    "line_2 = Line2D([tr_means[monsieur_idx], 0], [tr_means[sang_idx], 0], 1, lw=2, ls='--', c='darkgrey')\n",
    "line_3 = Line2D([tc_means[monsieur_idx], 0], [tc_means[sang_idx], 0], 1, lw=2, ls='--', c='darkgrey')\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.add_line(line_1)\n",
    "ax.add_line(line_2)\n",
    "ax.add_line(line_3)\n",
    "\n",
    "angle_plot = get_angle_plot(line_1, line_2, 50)\n",
    "ax.add_patch(angle_plot) # To display the angle arc\n",
    "\n",
    "angle_plot = get_angle_plot(line_1, line_3, 12)\n",
    "ax.add_patch(angle_plot) # To display the angle arc\n",
    "\n",
    "angle_plot = get_angle_plot(line_2, line_3, 25)\n",
    "ax.add_patch(angle_plot) # To display the angle arc\n",
    "\n",
    "plt.xlabel('monsieur')\n",
    "plt.ylabel('sang')\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, 1.1), ncol=3)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ecc8b3-f3b3-4727-83ee-6962e34fc5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_len(v):\n",
    "    \"\"\"Compute the length (or norm) of a vector.\"\"\"\n",
    "    return np.sqrt(np.sum(v ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9dbafa-5b6d-403a-a04f-7e921b88feed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_distance(a, b):\n",
    "    \"\"\"Compute the cosine distance between two vectors.\n",
    "\n",
    "    Arguments:\n",
    "        a (numpy.ndarray): a vector of floats or ints.\n",
    "        b (numpy.ndarray): a vector of floats or ints.\n",
    "\n",
    "    Returns:\n",
    "        float: cosine distance between vector a and b.\n",
    "\n",
    "    Note:\n",
    "        See also scipy.spatial.distance.cdist\n",
    "\n",
    "    Examples:\n",
    "        >>> import numpy as np\n",
    "        >>> a = np.array([1, 4, 2, 8])\n",
    "        >>> b = np.array([2, 1, 4, 7])\n",
    "        >>> round(cosine_distance(a, b), 2)\n",
    "        0.09\n",
    "\n",
    "    \"\"\"\n",
    "    return 1 - np.dot(a, b) / (vector_len(a) * vector_len(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116cf1c8-4965-4852-bf81-c415a1ffa7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc = cosine_distance(tragedy, comedy)\n",
    "print(f'tragédies - comédies:       {tc:.2f}')\n",
    "\n",
    "ttc = cosine_distance(tragedy, tragedy_comedy)\n",
    "print(f'tragédies - tragi-comédies: {ttc:.2f}')\n",
    "\n",
    "ctc = cosine_distance(comedy, tragedy_comedy)\n",
    "print(f' comédies - tragi-comédies: {ctc:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32124eb4-99c7-41b3-b0a1-594a3c1bcc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def city_block_distance(a, b):\n",
    "    \"\"\"Compute the city block distance between two vectors.\n",
    "\n",
    "    Arguments:\n",
    "        a (numpy.ndarray): a vector of floats or ints.\n",
    "        b (numpy.ndarray): a vector of floats or ints.\n",
    "\n",
    "    Returns:\n",
    "        {int, float}: The city block distance between vector a and b.\n",
    "\n",
    "    Examples:\n",
    "        >>> import numpy as np\n",
    "        >>> a = np.array([1, 4, 2, 8])\n",
    "        >>> b = np.array([2, 1, 4, 7])\n",
    "        >>> city_block_distance(a, b)\n",
    "        7\n",
    "\n",
    "    \"\"\"\n",
    "    return np.abs(a - b).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb6e186-1e9c-427a-b818-3c2351e3ab44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undocumented code snippet used in chapter (e.g., for figure generation)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "monsieur_trag = tr_means[monsieur_idx]\n",
    "sang_trag = tr_means[sang_idx]\n",
    "monsieur_com = co_means[monsieur_idx]\n",
    "sang_com = co_means[sang_idx]\n",
    "monsieur_tc = tc_means[monsieur_idx]\n",
    "sang_tc = tc_means[sang_idx]\n",
    "\n",
    "\n",
    "# trag-tc\n",
    "ax.plot([monsieur_trag, monsieur_tc], [sang_tc, sang_tc],\n",
    "        'C2', lw=2, ls='--')\n",
    "ax.plot([monsieur_trag, monsieur_trag], [sang_tc, sang_trag],\n",
    "        'C2', lw=2, ls='--')\n",
    "\n",
    "# com-tc\n",
    "ax.plot([monsieur_tc, monsieur_tc], [sang_tc, sang_com],\n",
    "        'C0', lw=2, ls='--')\n",
    "ax.plot([monsieur_tc, monsieur_com], [sang_com, sang_com],\n",
    "        'C0', lw=2, ls='--')\n",
    "\n",
    "# trag-com\n",
    "ax.plot([monsieur_trag, monsieur_com], [sang_trag, sang_trag],\n",
    "        'C1', lw=2, ls='--')\n",
    "ax.plot([monsieur_com, monsieur_com], [sang_trag, sang_com],\n",
    "        'C1', lw=2, ls='--')\n",
    "\n",
    "ax.scatter(co_means[monsieur_idx], co_means[sang_idx],\n",
    "           label='Comédies', zorder=3)\n",
    "ax.scatter(tr_means[monsieur_idx], tr_means[sang_idx],\n",
    "           label='Tragédie', zorder=3)\n",
    "ax.scatter(tc_means[monsieur_idx], tc_means[sang_idx],\n",
    "           label='Tragic-comédies', zorder=3)\n",
    "\n",
    "ax.set(xlabel='monsieur', ylabel='sang')\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, 1.1), ncol=3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d9f4a1-7378-43b0-aecb-76631b2560e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc = city_block_distance(tragedy, comedy)\n",
    "print(f'tragédies - comédies:       {tc:.2f}')\n",
    "\n",
    "ttc = city_block_distance(tragedy, tragedy_comedy)\n",
    "print(f'tragédies - tragi-comédies: {ttc:.2f}')\n",
    "\n",
    "ctc = city_block_distance(comedy, tragedy_comedy)\n",
    "print(f' comédies - tragi-comédies: {ctc:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb47d947-25ad-41cc-9f97-5074c8bc7874",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.spatial.distance as dist\n",
    "\n",
    "genre_vectors = {'tragédie': tr_means, 'comédie': co_means, 'tragi-comédie': tc_means}\n",
    "metrics = {'cosine': dist.cosine, 'manhattan': dist.cityblock, 'euclidean': dist.euclidean}\n",
    "\n",
    "import itertools\n",
    "\n",
    "for metric_name, metric_fn in metrics.items():\n",
    "    print(metric_name)\n",
    "    for v1, v2 in itertools.combinations(genre_vectors, 2):\n",
    "        distance = metric_fn(genre_vectors[v1], genre_vectors[v2])\n",
    "        print(f'   {v1} - {v2}: {distance:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c3337d-00fa-43ee-9bfc-20951e4f8d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neighbors(X, metric='cosine'):\n",
    "    \"\"\"Retrieve the nearest neighbor for each row in a 2D array.\n",
    "\n",
    "    Arguments:\n",
    "        X (numpy.ndarray): a 2D array.\n",
    "        metric (str): the distance metric to be used,\n",
    "            one of: 'cosine', 'manhattan', 'euclidean'\n",
    "\n",
    "    Returns:\n",
    "        neighbors (list): A list of integers, corresponding to\n",
    "            the index of each row's nearest neighbor.\n",
    "\n",
    "    Examples:\n",
    "        >>> X = np.array([[1, 4, 2], [5, 5, 1], [1, 2, 1]])\n",
    "        >>> nearest_neighbors(X, metric='manhattan')\n",
    "        [1, 0, 0]\n",
    "\n",
    "    \"\"\"\n",
    "    distances = dist.pdist(X, metric=metric)\n",
    "    distances = dist.squareform(distances)\n",
    "    np.fill_diagonal(distances, np.inf)\n",
    "    return distances.argmin(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c505836-d9f7-48c4-9426-50d8e20f11cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbor_indices = nearest_neighbors(document_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e168dbe-a5ad-44cf-ab01-0149f860fb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_genres = genres[neighbor_indices]\n",
    "print(nn_genres[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1c270a-dcd7-42e1-b0a4-6d414bc6ac44",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap = np.sum(genres == nn_genres)\n",
    "print(f'Maching pairs (normalized): {overlap / len(genres):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1895b602-0d60-47bf-ba8b-23f6cb4f9678",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(collections.Counter(nn_genres[genres == 'Tragédie']).most_common())\n",
    "print(collections.Counter(nn_genres[genres == 'Comédie']).most_common())\n",
    "print(collections.Counter(nn_genres[genres == 'Tragi-comédie']).most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e7364a-596b-4a29-94e6-7b3d62fc3660",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_dists, c_dists = [], []\n",
    "for tc in document_term_matrix[genres == 'Tragi-comédie']:\n",
    "    t_dists.append(cosine_distance(tc, tr_means))\n",
    "    c_dists.append(cosine_distance(tc, co_means))\n",
    "\n",
    "print(f'Mean distance to comédie vector: {np.mean(c_dists):.3f}')\n",
    "print(f'Mean distance to tragédie vector: {np.mean(t_dists):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3f935b-400c-4b18-8f82-834dedb4ed38",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.boxplot([t_dists, c_dists])\n",
    "ax.set(xticklabels=('Tragédie', 'Comédie'), ylabel='Distances to genre means');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc57e1b-2fda-4d2b-8afa-713dbbaea4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_dists = np.array(t_dists)\n",
    "outliers = t_dists.argsort()[::-1][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605598ec-4198-415b-a0fd-440ed46f4285",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc_titles = np.array(titles)[genres == 'Tragi-comédie']\n",
    "print('\\n'.join(tc_titles[outliers]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed515ebf-fad6-4c13-abfe-b84b60d4981c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "letters, years = [], []\n",
    "with open(\"data/chain-letters.csv\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        letters.append(row[\"letter\"])\n",
    "        years.append(int(row[\"year\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62818fa4-98b6-4e28-82ad-cadb68a1bc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b92324c-1dee-4788-ae19-d89ecf948887",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1.0, 0.5, 0.33, 0.25, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d58ac9-c8af-4a78-accf-0a1412287314",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 3, 6, 10, 15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51651a19-fb87-498d-947c-3bc47724dade",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([0, 1, 1, 2, 3, 5], dtype='int32')\n",
    "print(a.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a929d577-463c-4f03-af86-476c7323c03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.astype('float32')\n",
    "print(a.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a1b5cb-bd0d-4aea-bcc5-50d50372c208",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([0, 1, 1, 2, 3, 5])\n",
    "print(a.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d030aab2-c789-43d4-a539-bb06801ca33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[0, 1, 2], [1, 0, 2], [2, 1, 0]])\n",
    "print(a.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bba0580-722b-4ff6-b2e5-e755f07497ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[[1, 3, 3], [2, 5, 2]], [[2, 3, 7], [4, 5, 9]]])\n",
    "print(a.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8907fe01-f288-4e23-9f1a-470ca4ec4baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[0, 1, 2, 3], [1, 0, 2, 6], [2, 1, 0, 5]])\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf0234d-29c1-458d-af81-ac16b8aa7eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.zeros((3, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6955b939-5f81-454b-a30c-cb0154424470",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.zeros(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a98aad6-8a9e-4044-9ffe-44e111eb3966",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.ones((3, 4), dtype='int64'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6d540a-5978-4a29-9774-cc22374d248c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.empty((3, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e815430-7bf7-4faf-8161-70426e793b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.random.random_sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e55ba9c-41e4-4e54-9831-9e273d0756cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.random.random_sample((2, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5b6502-3fc0-4dcb-b6f3-2d3bb4423347",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(0, 2, 0.25)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ab0b6a-d619-48c3-b0f8-475eaf98401b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(10)\n",
    "print(a[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d657fd7-c2f9-486d-8570-275387b10c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a[3:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da7e8fb-4b56-4bf7-97dc-1914e8da2f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = vocabulary.index('monsieur')\n",
    "document_term_matrix = np.array(document_term_matrix)\n",
    "print(document_term_matrix[2, word_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4828cf-272c-4dac-8bfd-bbdecd9e1a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(document_term_matrix[:5, word_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69bfcd1-5ad9-4def-ac1e-afa2733ec2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(document_term_matrix[5, 10:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14fef75-f63a-4c5b-88dd-627c2a28878e",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_values = document_term_matrix[:, word_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528f48c3-e0d5-435e-acaf-4208a09b6662",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(document_term_matrix[5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162cb2fb-7359-4371-bb35-9367dc52e7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(document_term_matrix[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712ad8f1-9fb7-40db-9397-a810e44c1ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(document_term_matrix[(1, 8, 3), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca75b81-a6fb-4bd6-bb9e-e525bf5cf5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = 'monsieur', 'madame', 'amour'\n",
    "word_indexes = [vocabulary.index(word) for word in words]\n",
    "print(document_term_matrix[:, word_indexes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32920fad-a956-4d54-8202-a055c1183297",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21199d9c-1787-4345-b2b8-3118fb665e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([number * 10 for number in numbers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b304e796-2fff-49a1-88e5-0474e3cb56be",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = np.array(numbers)\n",
    "print(numbers * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e91aa00-ca6d-4b44-8f01-518eaed6e1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = list(range(1000000))\n",
    "%timeit [number * 10 for number in numbers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a60cd3-b780-4127-9ee2-6915d0dc829f",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = np.arange(1000000)\n",
    "%timeit numbers * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede05e5e-e744-42e8-940c-c4f5f3d8650e",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55]\n",
    "print([number for number in numbers if number < 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0248bc-aa6e-4e7b-8997-c3ec9632eb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = np.array(numbers)\n",
    "print(numbers[numbers < 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b2afab-38db-4236-a8cf-f6c57f822b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numbers < 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec141526-b434-4ee6-bf4d-39be05ba481c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(document_term_matrix[document_term_matrix[:, vocabulary.index('de')] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fafcaa6-b294-4c1c-9aad-3754491dde59",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = np.random.random_sample(100000)\n",
    "print(sum(numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e4d944-2559-411d-9fcc-4edd7908152d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numbers.sum())  # equivalent to np.sum(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4a796f-ce5a-489d-8c0b-71f82706703f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit sum(numbers)\n",
    "%timeit numbers.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13ff3a3-2a26-4556-b9d4-11cbd83c73aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sums = document_term_matrix.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c54e48-e96e-422d-9ac2-ac5302b493d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(document_term_matrix.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178b576a-ddb9-42c0-b74d-bac5993a85bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(document_term_matrix.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8eedbb7-119c-4a0b-a1ee-baa46bb8362d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "b = np.array([2, 4, 6])\n",
    "print(a * b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d991a4-69cd-4372-ba38-02c4292c763d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "a = np.array([1, 2, 3])\n",
    "print(a * 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
